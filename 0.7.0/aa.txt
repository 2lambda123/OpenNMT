|      | `OpenNMT-py` | `OpenNMT-lua` |
| ---  | ---          | ---           |
| `-config`<br>`-save_config` |  | *not supported* |
| `-sample`-<br>`-sample_type`-<br>`-sample_perplexity_init`-<br>`-sample_perplexity_max`-<br>`-sample_vocab`  | Sampled dataset options | *not supported* |
| `-model_type` | lm, seq2seq, seqtagger | *not supported* |
| `-enc_layers` | number of layers of the encoder | *not supported*: see `-layers` |
| `-dec_layers` | number of layers of the encoder | *not supported*: see `-layers` |
| `-src_word_vec_size` |  | *not supported*: see `-word_vec_size` and `-feat_vec_size` |
| `-tgt_word_vec_size` |  | *not supported*: see `-word_vec_size` and `-feat_vec_size` |
| `-fix_word_vecs_enc` | true, false, pretrained | *not supported* |
| `-fix_word_vecs_dec` | true, false, pretrained |  |
| `-share_decoder_embeddings` | *not supported* | share the word and softmax embeddings for decoder |
| `-feat_merge` | concat, sum | concat, sum, mlp |
| `-dropout_input` | Dropout probability applied to the input of the recurrent module | *not supported* |
| `-dropout_words` | Dropout probability applied to the source sequence | *not supported* |
| `-dropout_type` | naive, variational | *not supported* |
| `-residual` | Add residual connections between recurrent layers | *not supported* |
| `-bridge` | copy, dense, dense_nonlinear | *not supported* |
| `-encoder_type` | rnn, brnn, dbrnn, pdbrnn, gnmt, cnn | text, img: if text, type is defined by `-encoder_layer` and `-brnn` |
| `-encoder_layer` | *not supported* | rnn, mean, transformer |
| `-decoder_layer` | *not supported* | rnn, transformer |
| `-brnn` | defined by `-encoder_type` | use a bidirectional encoder, if `-encoder_layer` is `-rnn` |
| `-pdbrnn_reduction`<br>`-pdbrnn_merge` | for `-encoder_type` set to `-pdbrnn` | *not supported* |
| `-cnn_layers`<br>`-cnn_kernel`<br>`-cnn_size` | for `-encoder_type` set to `-cnn` | *not supported* |
| `-truncated_decoder` | *not supported* | truncated bptt |
| `-attention` | none, global | only global attention |
| `-attention_type` | see `-global_attention` | dot, general, mlp |
| `-global_attention` | general, dot, concat | see `-attention_type` |
| `-copy_attn` | *not supported* | copy attention layer |
| `-coverage_attn` | *not supported* | coverage attention layer |
| `-lambda_coverage` |  | lambda value for coverage |
| `-context_gate` |  | source,target,both |
| `-use_pos_emb` | add positional embeddings to word embeddings | *not supported* |
| `-max_pos` | connected to `-use_pos_emb` | *not supported* |
| `-position_encoding` | *not supported* | use a sinusoid to mark relative words positions. |
| `-save_every` |  | *not supported* |
| `-save_every_epochs` |  | *not supported* |
| `-report_every` |  | *not supported* |
| `-async_parallel`<br>`-async_parallel_minbatch` | Async multi-gpu training | *not supported* |
| `-start_iteration` |  |  |
| `-end_epoch` | the final epoch of the training | *not supported*: see `-epochs` |
| `-epochs` | *not supported*: see `-end_epoch` | number of training epochs |
| `-validation_metric` | perplexity, loss, bleu, ter, dlratio | *not supported* |
| `-save_validation_translation_every` |  | *not supported* |
| `-max_batch_size` | maximum batch size | *not supported*: see `-max_generator_batches` |
| `-uneven_batches` |  |  |
| `-max_generator_batches` | *not supported* |  |
| `-min_learning_rate` | do not continue the training past this learning rate value | *not supported* |
| `-start_decay_score_delta` |  | *not supported* |
| `-decay` |  |  |
| `-decay_method` |  | use a custom learning rate decay (?) |
| `-warmup_steps` | *not supported* | number of warmup steps for custom decay |
| `-train_from_state_dict` | *not supported* |  |
| `-continue` |  | *not supported* |
| `-extra_shuffle` | *not supported* | shuffle and re-assign mini-batches |
| `-start_checkpoint_at` | *not supported* |  |
| `-gpus` | is `-gpuid` | list of GPU identifiers for parallel training |
| `-gpuid` | list of GPU identifiers for parallel training | is `-gpus` |
| `-log_interval` | *not supported* | print stats at this interval |
| `-log_server` |  | see `-exp_host` and `-exp_port` |
| `-exp_host, exp_port` | see `-log_server` |  |
| `-experiment_name` | is `-exp` | crayon experiment name |
| `-exp` | crayon experiment name | is `-experiment name` |
| `-fp16` | half-float precision for GPU | *not supported* |
| `-fallback_to_cpu` |  | *not supported* |
| `-no_nccl` |  | *not supported* |
