|      | `OpenNMT-lua` | `OpenNMT-py` |
| ---  | ---           | ---          |
| `-config`<br>`-save_config` | *not supported* |  |
| `-sample`-<br>`-sample_type`-<br>`-sample_perplexity_init`-<br>`-sample_perplexity_max`-<br>`-sample_vocab`  | *not supported* | Sampled dataset options |
| `-model_type` | *not supported* | lm, seq2seq, seqtagger |
| `-enc_layers` | *not supported*: see `-layers` | number of layers of the encoder |
| `-dec_layers` | *not supported*: see `-layers` | number of layers of the encoder |
| `-src_word_vec_size` | *not supported*: see `-word_vec_size` and `-feat_vec_size` |  |
| `-tgt_word_vec_size` | *not supported*: see `-word_vec_size` and `-feat_vec_size` |  |
| `-fix_word_vecs_enc` | *not supported* | true, false, pretrained |
| `-fix_word_vecs_dec` |  | true, false, pretrained |
| `-share_decoder_embeddings` | share the word and softmax embeddings for decoder | *not supported* |
| `-feat_merge` | concat, sum, mlp | concat, sum |
| `-dropout_input` | *not supported* | Dropout probability applied to the input of the recurrent module |
| `-dropout_words` | *not supported* | Dropout probability applied to the source sequence |
| `-dropout_type` | *not supported* | naive, variational |
| `-residual` | *not supported* | Add residual connections between recurrent layers |
| `-bridge` | *not supported* | copy, dense, dense_nonlinear |
| `-encoder_type` | text, img: if text, type is defined by `-encoder_layer` and `-brnn` | rnn, brnn, dbrnn, pdbrnn, gnmt, cnn |
| `-encoder_layer` | rnn, mean, transformer | *not supported* |
| `-decoder_layer` | rnn, transformer | *not supported* |
| `-brnn` | use a bidirectional encoder, if `-encoder_layer` is `-rnn` | defined by `-encoder_type` |
| `-pdbrnn_reduction`<br>`-pdbrnn_merge` | *not supported* | for `-encoder_type` set to `-pdbrnn` |
| `-cnn_layers`<br>`-cnn_kernel`<br>`-cnn_size` | *not supported* | for `-encoder_type` set to `-cnn` |
| `-truncated_decoder` | truncated bptt | *not supported* |
| `-attention` | only global attention | none, global |
| `-attention_type` | dot, general, mlp | see `-global_attention` |
| `-global_attention` | see `-attention_type` | general, dot, concat |
| `-copy_attn` | copy attention layer | *not supported* |
| `-coverage_attn` | coverage attention layer | *not supported* |
| `-lambda_coverage` | lambda value for coverage |  |
| `-context_gate` | source,target,both |  |
| `-use_pos_emb` | *not supported* | add positional embeddings to word embeddings |
| `-max_pos` | *not supported* | connected to `-use_pos_emb` |
| `-position_encoding` | use a sinusoid to mark relative words positions. | *not supported* |
| `-save_every` | *not supported* |  |
| `-save_every_epochs` | *not supported* |  |
| `-report_every` | *not supported* |  |
| `-async_parallel`<br>`-async_parallel_minbatch` | *not supported* | Async multi-gpu training |
| `-start_iteration` |  |  |
| `-end_epoch` | *not supported*: see `-epochs` | the final epoch of the training |
| `-epochs` | number of training epochs | *not supported*: see `-end_epoch` |
| `-validation_metric` | *not supported* | perplexity, loss, bleu, ter, dlratio |
| `-save_validation_translation_every` | *not supported* |  |
| `-max_batch_size` | *not supported*: see `-max_generator_batches` | maximum batch size |
| `-uneven_batches` |  |  |
| `-max_generator_batches` |  | *not supported* |
| `-min_learning_rate` | *not supported* | do not continue the training past this learning rate value |
| `-start_decay_score_delta` | *not supported* |  |
| `-decay` |  |  |
| `-decay_method` | use a custom learning rate decay (?) |  |
| `-warmup_steps` | number of warmup steps for custom decay | *not supported* |
| `-train_from_state_dict` |  | *not supported* |
| `-continue` | *not supported* |  |
| `-extra_shuffle` | shuffle and re-assign mini-batches | *not supported* |
| `-start_checkpoint_at` |  | *not supported* |
| `-gpus` | list of GPU identifiers for parallel training | is `-gpuid` |
| `-gpuid` | is `-gpus` | list of GPU identifiers for parallel training |
| `-log_interval` | print stats at this interval | *not supported* |
| `-log_server` | see `-exp_host` and `-exp_port` |  |
| `-exp_host, exp_port` |  | see `-log_server` |
| `-experiment_name` | crayon experiment name | is `-exp` |
| `-exp` | is `-experiment name` | crayon experiment name |
| `-fp16` | *not supported* | half-float precision for GPU |
| `-fallback_to_cpu` | *not supported* |  |
| `-no_nccl` | *not supported* |  |
