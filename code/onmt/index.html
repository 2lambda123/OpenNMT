<html>
<head>
<link rel="stylesheet" type="text/css" href="style.css">
<title>onmt - Documentation</title>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          skipTags: ['script', 'noscript', 'style', 'textarea'],
          displayMath: [['$${', '}$$']],
          inlineMath: [['${', '}$']]
      }
  });
  MathJax.Hub.Queue(function() {
      // Fix <code> tags after MathJax finishes running. This is a
      // hack to overcome a shortcoming of Markdown. Discussion at
      // https://github.com/mojombo/jekyll/issues/199
      var all = MathJax.Hub.getAllJax(), i;
      for(i = 0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
<link rel="stylesheet" href="../_highlight/styles/github.css">
<script type="text/javascript" src="../_highlight/highlight.pack.js"></script>
<script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        $('pre code').each(function(i, e) {
            var par = $(e).closest('pre');
            if (! $(par).hasClass('has-jax')) {
                hljs.highlightBlock(e);
            }
        });
    });
</script>



<script src="../search.js"></script>
<script type="text/javascript"> addSearchFormHeader(); </script>
<script type="text/javascript">
$(document).ready(function() {
    /* Fix up any badly formed anchors */
    $("a").each(function(i, e) {
        if (!e.href) {
            $(e).addClass('anchor');
            var inner = $(e).html();
            $(e).html("");
            $(e).after(inner);
        }
    })
})
</script>
</head>
<body>
<header>
<ul>Navigation:
<li><a href="../index.html">research-docs</a></li>
<li><a href="">onmt github</a></li>
<li><a href="#">top of this page</a></li>
</ul>
</header>
<div class="wrapper">
<div id="navcontainer"><ul>
       <li><a href="#onmt.Constants.dok">Constants</a>
       <ul>
              <li><a href="#onmt.Constants.dok"></a></li>
       </ul>
       </li>
       <li><a href="#onmt.Factory.dok">Factory</a>
       <ul>
              <li><a href="#onmt.Factory.dok"></a></li>
       </ul>
       </li>
       <li><a href="#onmt.LanguageModel.dok">LanguageModel</a>
       <ul>
              <li><a href="#onmt.LanguageModel.dok"></a><ul>
<li><a href="#onmt.LanguageModel.modelName">onmt.LanguageModel.modelName</a></li>
<li><a href="#onmt.LanguageModel.dataType">onmt.LanguageModel.dataType</a></li>
<li><a href="#onmt.LanguageModel.declareOpts">onmt.LanguageModel.declareOpts</a></li>
<li><a href="#onmt.LanguageModel">onmt.LanguageModel</a></li>
<li><a href="#onmt.LanguageModel.load">onmt.LanguageModel.load</a></li>
<li><a href="#onmt.LanguageModel:enableProfiling">onmt.LanguageModel:enableProfiling</a></li>
<li><a href="#onmt.LanguageModel:getOutput">onmt.LanguageModel:getOutput</a></li>
<li><a href="#onmt.LanguageModel:forwardComputeLoss">onmt.LanguageModel:forwardComputeLoss</a></li>
<li><a href="#onmt.LanguageModel:trainNetwork">onmt.LanguageModel:trainNetwork</a></li>
</ul>
</li>
       </ul>
       </li>
       <li><a href="#onmt.Model.dok">Model</a>
       <ul>
              <li><a href="#onmt.Model.dok"></a><ul>
<li><a href="#onmt.Model:changeParameters">onmt.Model:changeParameters</a></li>
<li><a href="#onmt.Model.declareOpts">onmt.Model.declareOpts</a></li>
<li><a href="#onmt.Model">onmt.Model</a></li>
<li><a href="#onmt.Model:getInputLabelsCount">onmt.Model:getInputLabelsCount</a></li>
<li><a href="#onmt.Model:getOutputLabelsCount">onmt.Model:getOutputLabelsCount</a></li>
<li><a href="#onmt.Model:evaluate">onmt.Model:evaluate</a></li>
<li><a href="#onmt.Model:training">onmt.Model:training</a></li>
<li><a href="#onmt.Model:initParams">onmt.Model:initParams</a></li>
</ul>
</li>
       </ul>
       </li>
       <li><a href="#onmt.ModelSelector.dok">ModelSelector</a>
       <ul>
              <li><a href="#onmt.ModelSelector.dok"></a></li>
       </ul>
       </li>
       <li><a href="#onmt.Seq2Seq.dok">Seq2Seq</a>
       <ul>
              <li><a href="#onmt.Seq2Seq.dok"></a><ul>
<li><a href="#onmt.Seq2Seq.modelName">onmt.Seq2Seq.modelName</a></li>
<li><a href="#onmt.Seq2Seq.dataType">onmt.Seq2Seq.dataType</a></li>
<li><a href="#onmt.Seq2Seq.declareOpts">onmt.Seq2Seq.declareOpts</a></li>
<li><a href="#onmt.Seq2Seq">onmt.Seq2Seq</a></li>
<li><a href="#onmt.Seq2Seq.load">onmt.Seq2Seq.load</a></li>
<li><a href="#onmt.Seq2Seq:returnIndividualLosses">onmt.Seq2Seq:returnIndividualLosses</a></li>
<li><a href="#onmt.Seq2Seq:enableProfiling">onmt.Seq2Seq:enableProfiling</a></li>
<li><a href="#onmt.Seq2Seq:getOutput">onmt.Seq2Seq:getOutput</a></li>
<li><a href="#onmt.Seq2Seq:maskPadding">onmt.Seq2Seq:maskPadding</a></li>
<li><a href="#onmt.Seq2Seq:forwardComputeLoss">onmt.Seq2Seq:forwardComputeLoss</a></li>
<li><a href="#onmt.Seq2Seq:trainNetwork">onmt.Seq2Seq:trainNetwork</a></li>
</ul>
</li>
       </ul>
       </li>
       <li><a href="#onmt.SeqTagger.dok">SeqTagger</a>
       <ul>
              <li><a href="#onmt.SeqTagger.dok"></a><ul>
<li><a href="#onmt.SeqTagger.modelName">onmt.SeqTagger.modelName</a></li>
<li><a href="#onmt.SeqTagger.dataType">onmt.SeqTagger.dataType</a></li>
<li><a href="#onmt.SeqTagger.declareOpts">onmt.SeqTagger.declareOpts</a></li>
<li><a href="#onmt.SeqTagger">onmt.SeqTagger</a></li>
<li><a href="#onmt.SeqTagger.load">onmt.SeqTagger.load</a></li>
<li><a href="#onmt.SeqTagger:enableProfiling">onmt.SeqTagger:enableProfiling</a></li>
<li><a href="#onmt.SeqTagger:getOutput">onmt.SeqTagger:getOutput</a></li>
<li><a href="#onmt.SeqTagger:forwardComputeLoss">onmt.SeqTagger:forwardComputeLoss</a></li>
<li><a href="#onmt.SeqTagger:trainNetwork">onmt.SeqTagger:trainNetwork</a></li>
</ul>
</li>
       </ul>
       </li>
       <li><a href="#onmt.data.dok">data</a>
       <ul>
              <li><a href="#onmt.data.AliasMultinomial.dok">AliasMultinomial</a></li>
              <li><a href="#onmt.data.Batch.dok">Batch</a><ul>
<li><a href="#onmt.Batch">onmt.Batch</a></li>
<li><a href="#onmt.Batch:setSourceInput">onmt.Batch:setSourceInput</a></li>
<li><a href="#onmt.Batch:setTargetInput">onmt.Batch:setTargetInput</a></li>
<li><a href="#onmt.Batch:setTargetOutput">onmt.Batch:setTargetOutput</a></li>
<li><a href="#onmt.Batch:getSourceInput">onmt.Batch:getSourceInput</a></li>
<li><a href="#onmt.Batch:getTargetInput">onmt.Batch:getTargetInput</a></li>
<li><a href="#onmt.Batch:getTargetOutput">onmt.Batch:getTargetOutput</a></li>
</ul>
</li>
              <li><a href="#onmt.data.BatchTensor.dok">BatchTensor</a><ul>
<li><a href="#onmt.BatchTensor">onmt.BatchTensor</a></li>
<li><a href="#onmt.BatchTensor:getSourceInput">onmt.BatchTensor:getSourceInput</a></li>
</ul>
</li>
              <li><a href="#onmt.data.Dataset.dok">Dataset</a><ul>
<li><a href="#onmt.Dataset">onmt.Dataset</a></li>
<li><a href="#onmt.Dataset:setBatchSize">onmt.Dataset:setBatchSize</a></li>
<li><a href="#onmt.Dataset:batchCount">onmt.Dataset:batchCount</a></li>
<li><a href="#onmt.Dataset:getBatch">onmt.Dataset:getBatch</a></li>
</ul>
</li>
              <li><a href="#onmt.data.Preprocessor.dok">Preprocessor</a></li>
              <li><a href="#onmt.data.SampledDataset.dok">SampledDataset</a><ul>
<li><a href="#onmt.SampledDataset">onmt.SampledDataset</a></li>
<li><a href="#onmt.SampledDataset:sample">onmt.SampledDataset:sample</a></li>
<li><a href="#onmt.SampledDataset:getPpl">onmt.SampledDataset:getPpl</a></li>
<li><a href="#onmt.SampledDataset:setLoss">onmt.SampledDataset:setLoss</a></li>
<li><a href="#onmt.SampledDataset:setBatchSize">onmt.SampledDataset:setBatchSize</a></li>
<li><a href="#onmt.SampledDataset:getNumSampled">onmt.SampledDataset:getNumSampled</a></li>
<li><a href="#onmt.SampledDataset:batchCount">onmt.SampledDataset:batchCount</a></li>
<li><a href="#onmt.SampledDataset:getBatch">onmt.SampledDataset:getBatch</a></li>
<li><a href="#onmt.SampledDataset.declareOpts">onmt.SampledDataset.declareOpts</a></li>
<li><a href="#onmt.SampledDataset:checkModel">onmt.SampledDataset:checkModel</a></li>
<li><a href="#onmt.SampledDataset:needIndividualLosses">onmt.SampledDataset:needIndividualLosses</a></li>
</ul>
</li>
              <li><a href="#onmt.data.Vocabulary.dok">Vocabulary</a></li>
              <li><a href="#onmt.data.init.dok">init</a></li>
       </ul>
       </li>
       <li><a href="#onmt.init.dok">init</a>
       <ul>
              <li><a href="#onmt.init.dok"></a></li>
       </ul>
       </li>
       <li><a href="#onmt.modules.dok">modules</a>
       <ul>
              <li><a href="#onmt.modules.BiEncoder.dok">BiEncoder</a><ul>
<li><a href="#onmt.BiEncoder">onmt.BiEncoder</a></li>
<li><a href="#onmt.BiEncoder.load">onmt.BiEncoder.load</a></li>
<li><a href="#onmt.BiEncoder:serialize">onmt.BiEncoder:serialize</a></li>
<li><a href="#onmt.BiEncoder:contextSize">onmt.BiEncoder:contextSize</a></li>
<li><a href="#onmt.BiEncoder.declareOpts">onmt.BiEncoder.declareOpts</a></li>
<li><a href="#onmt.BiEncoder:resetPreallocation">onmt.BiEncoder:resetPreallocation</a></li>
<li><a href="#onmt.BiEncoder:maskPadding">onmt.BiEncoder:maskPadding</a></li>
<li><a href="#onmt.BiEncoder:forward">onmt.BiEncoder:forward</a></li>
<li><a href="#onmt.BiEncoder:backward">onmt.BiEncoder:backward</a></li>
</ul>
</li>
              <li><a href="#onmt.modules.DBiEncoder.dok">DBiEncoder</a><ul>
<li><a href="#onmt.DBiEncoder">onmt.DBiEncoder</a></li>
<li><a href="#onmt.DBiEncoder.load">onmt.DBiEncoder.load</a></li>
<li><a href="#onmt.DBiEncoder:serialize">onmt.DBiEncoder:serialize</a></li>
<li><a href="#onmt.DBiEncoder:contextSize">onmt.DBiEncoder:contextSize</a></li>
<li><a href="#onmt.DBiEncoder.declareOpts">onmt.DBiEncoder.declareOpts</a></li>
<li><a href="#onmt.DBiEncoder:resetPreallocation">onmt.DBiEncoder:resetPreallocation</a></li>
<li><a href="#onmt.DBiEncoder:maskPadding">onmt.DBiEncoder:maskPadding</a></li>
<li><a href="#onmt.DBiEncoder:forward">onmt.DBiEncoder:forward</a></li>
<li><a href="#onmt.DBiEncoder:backward">onmt.DBiEncoder:backward</a></li>
</ul>
</li>
              <li><a href="#onmt.modules.Decoder.dok">Decoder</a><ul>
<li><a href="#onmt.Decoder">onmt.Decoder</a></li>
<li><a href="#onmt.Decoder.load">onmt.Decoder.load</a></li>
<li><a href="#onmt.Decoder:serialize">onmt.Decoder:serialize</a></li>
<li><a href="#onmt.Decoder:maskPadding">onmt.Decoder:maskPadding</a></li>
<li><a href="#onmt.Decoder:forwardOne">onmt.Decoder:forwardOne</a></li>
<li><a href="#onmt.Decoder:forward">onmt.Decoder:forward</a></li>
<li><a href="#onmt.Decoder:backward">onmt.Decoder:backward</a></li>
<li><a href="#onmt.Decoder:computeLoss">onmt.Decoder:computeLoss</a></li>
<li><a href="#onmt.Decoder:computeScore">onmt.Decoder:computeScore</a></li>
<li><a href="#onmt.Decoder.declareOpts">onmt.Decoder.declareOpts</a></li>
<li><a href="#onmt.Decoder:returnIndividualLosses">onmt.Decoder:returnIndividualLosses</a></li>
<li><a href="#onmt.Decoder:resetPreallocation">onmt.Decoder:resetPreallocation</a></li>
<li><a href="#onmt.Decoder:findAttentionModel">onmt.Decoder:findAttentionModel</a></li>
<li><a href="#onmt.Decoder:forwardAndApply">onmt.Decoder:forwardAndApply</a></li>
</ul>
</li>
              <li><a href="#onmt.modules.Encoder.dok">Encoder</a><ul>
<li><a href="#onmt.Encoder">onmt.Encoder</a></li>
<li><a href="#onmt.Encoder.load">onmt.Encoder.load</a></li>
<li><a href="#onmt.Encoder:serialize">onmt.Encoder:serialize</a></li>
<li><a href="#onmt.Encoder:contextSize">onmt.Encoder:contextSize</a></li>
<li><a href="#onmt.Encoder:forward">onmt.Encoder:forward</a></li>
<li><a href="#onmt.Encoder:backward">onmt.Encoder:backward</a></li>
<li><a href="#onmt.Encoder.declareOpts">onmt.Encoder.declareOpts</a></li>
<li><a href="#onmt.Encoder:resetPreallocation">onmt.Encoder:resetPreallocation</a></li>
<li><a href="#onmt.Encoder:maskPadding">onmt.Encoder:maskPadding</a></li>
</ul>
</li>
              <li><a href="#onmt.modules.FeaturesEmbedding.dok">FeaturesEmbedding</a></li>
              <li><a href="#onmt.modules.FeaturesGenerator.dok">FeaturesGenerator</a><ul>
<li><a href="#onmt.FeaturesGenerator">onmt.FeaturesGenerator</a></li>
</ul>
</li>
              <li><a href="#onmt.modules.GRU.dok">GRU</a><ul>
<li><a href="#onmt.GRU">onmt.GRU</a></li>
</ul>
</li>
              <li><a href="#onmt.modules.Generator.dok">Generator</a></li>
              <li><a href="#onmt.modules.GlobalAttention.dok">GlobalAttention</a><ul>
<li><a href="#onmt.GlobalAttention">onmt.GlobalAttention</a></li>
<li><a href="#onmt.GlobalAttention.declareOpts">onmt.GlobalAttention.declareOpts</a></li>
</ul>
</li>
              <li><a href="#onmt.modules.JoinReplicateTable.dok">JoinReplicateTable</a></li>
              <li><a href="#onmt.modules.LSTM.dok">LSTM</a><ul>
<li><a href="#onmt.LSTM">onmt.LSTM</a></li>
</ul>
</li>
              <li><a href="#onmt.modules.MaskedSoftmax.dok">MaskedSoftmax</a><ul>
<li><a href="#onmt.MaskedSoftmax">onmt.MaskedSoftmax</a></li>
</ul>
</li>
              <li><a href="#onmt.modules.Network.dok">Network</a></li>
              <li><a href="#onmt.modules.NoAttention.dok">NoAttention</a><ul>
<li><a href="#onmt.NoAttention">onmt.NoAttention</a></li>
</ul>
</li>
              <li><a href="#onmt.modules.PDBiEncoder.dok">PDBiEncoder</a><ul>
<li><a href="#onmt.PDBiEncoder">onmt.PDBiEncoder</a></li>
<li><a href="#onmt.PDBiEncoder.load">onmt.PDBiEncoder.load</a></li>
<li><a href="#onmt.PDBiEncoder:serialize">onmt.PDBiEncoder:serialize</a></li>
<li><a href="#onmt.PDBiEncoder:contextSize">onmt.PDBiEncoder:contextSize</a></li>
<li><a href="#onmt.PDBiEncoder.declareOpts">onmt.PDBiEncoder.declareOpts</a></li>
<li><a href="#onmt.PDBiEncoder:resetPreallocation">onmt.PDBiEncoder:resetPreallocation</a></li>
<li><a href="#onmt.PDBiEncoder:maskPadding">onmt.PDBiEncoder:maskPadding</a></li>
<li><a href="#onmt.PDBiEncoder:forward">onmt.PDBiEncoder:forward</a></li>
<li><a href="#onmt.PDBiEncoder:backward">onmt.PDBiEncoder:backward</a></li>
</ul>
</li>
              <li><a href="#onmt.modules.ParallelClassNLLCriterion.dok">ParallelClassNLLCriterion</a></li>
              <li><a href="#onmt.modules.Sequencer.dok">Sequencer</a><ul>
<li><a href="#onmt.Sequencer">onmt.Sequencer</a></li>
<li><a href="#onmt.Sequencer:net">onmt.Sequencer:net</a></li>
<li><a href="#onmt.Sequencer:cloneId">onmt.Sequencer:cloneId</a></li>
<li><a href="#onmt.Sequencer:training">onmt.Sequencer:training</a></li>
<li><a href="#onmt.Sequencer:evaluate">onmt.Sequencer:evaluate</a></li>
</ul>
</li>
              <li><a href="#onmt.modules.WordEmbedding.dok">WordEmbedding</a><ul>
<li><a href="#onmt.WordEmbedding">onmt.WordEmbedding</a></li>
<li><a href="#onmt.WordEmbedding:postParametersInitialization">onmt.WordEmbedding:postParametersInitialization</a></li>
<li><a href="#onmt.WordEmbedding:fixEmbeddings">onmt.WordEmbedding:fixEmbeddings</a></li>
<li><a href="#onmt.WordEmbedding:accGradParameters">onmt.WordEmbedding:accGradParameters</a></li>
<li><a href="#onmt.WordEmbedding:parameters">onmt.WordEmbedding:parameters</a></li>
</ul>
</li>
              <li><a href="#onmt.modules.init.dok">init</a></li>
       </ul>
       </li>
       <li><a href="#onmt.tagger.dok">tagger</a>
       <ul>
              <li><a href="#onmt.tagger.Tagger.dok">Tagger</a><ul>
<li><a href="#onmt.Tagger:tag">onmt.Tagger:tag</a></li>
<li><a href="#onmt.Tagger.declareOpts">onmt.Tagger.declareOpts</a></li>
<li><a href="#onmt.Tagger">onmt.Tagger</a></li>
<li><a href="#onmt.Tagger:buildInput">onmt.Tagger:buildInput</a></li>
<li><a href="#onmt.Tagger:buildOutput">onmt.Tagger:buildOutput</a></li>
<li><a href="#onmt.Tagger:buildData">onmt.Tagger:buildData</a></li>
<li><a href="#onmt.Tagger:buildTargetWords">onmt.Tagger:buildTargetWords</a></li>
<li><a href="#onmt.Tagger:buildTargetFeatures">onmt.Tagger:buildTargetFeatures</a></li>
<li><a href="#onmt.Tagger:tagBatch">onmt.Tagger:tagBatch</a></li>
</ul>
</li>
              <li><a href="#onmt.tagger.init.dok">init</a></li>
       </ul>
       </li>
       <li><a href="#onmt.train.dok">train</a>
       <ul>
              <li><a href="#onmt.train.Checkpoint.dok">Checkpoint</a><ul>
<li><a href="#onmt.Checkpoint:saveIteration">onmt.Checkpoint:saveIteration</a></li>
<li><a href="#onmt.Checkpoint.declareOpts">onmt.Checkpoint.declareOpts</a></li>
<li><a href="#onmt.Checkpoint">onmt.Checkpoint</a></li>
<li><a href="#onmt.Checkpoint:save">onmt.Checkpoint:save</a></li>
<li><a href="#onmt.Checkpoint:saveEpoch">onmt.Checkpoint:saveEpoch</a></li>
<li><a href="#onmt.Checkpoint.loadFromCheckpoint">onmt.Checkpoint.loadFromCheckpoint</a></li>
</ul>
</li>
              <li><a href="#onmt.train.EpochState.dok">EpochState</a><ul>
<li><a href="#onmt.EpochState">onmt.EpochState</a></li>
<li><a href="#onmt.EpochState:update">onmt.EpochState:update</a></li>
<li><a href="#onmt.EpochState:log">onmt.EpochState:log</a></li>
<li><a href="#onmt.EpochState:reset">onmt.EpochState:reset</a></li>
<li><a href="#onmt.EpochState:getTime">onmt.EpochState:getTime</a></li>
</ul>
</li>
              <li><a href="#onmt.train.Optim.dok">Optim</a><ul>
<li><a href="#onmt.Optim:updateLearningRate">onmt.Optim:updateLearningRate</a></li>
<li><a href="#onmt.Optim.declareOpts">onmt.Optim.declareOpts</a></li>
<li><a href="#onmt.Optim">onmt.Optim</a></li>
<li><a href="#onmt.Optim:setOptimStates">onmt.Optim:setOptimStates</a></li>
<li><a href="#onmt.Optim:zeroGrad">onmt.Optim:zeroGrad</a></li>
<li><a href="#onmt.Optim:prepareGrad">onmt.Optim:prepareGrad</a></li>
<li><a href="#onmt.Optim:updateParams">onmt.Optim:updateParams</a></li>
<li><a href="#onmt.Optim:getLearningRate">onmt.Optim:getLearningRate</a></li>
<li><a href="#onmt.Optim:getStates">onmt.Optim:getStates</a></li>
</ul>
</li>
              <li><a href="#onmt.train.Trainer.dok">Trainer</a></li>
              <li><a href="#onmt.train.init.dok">init</a></li>
       </ul>
       </li>
       <li><a href="#onmt.translate.dok">translate</a>
       <ul>
              <li><a href="#onmt.translate.Advancer.dok">Advancer</a><ul>
<li><a href="#onmt.Advancer:initBeam">onmt.Advancer:initBeam</a></li>
<li><a href="#onmt.Advancer:update">onmt.Advancer:update</a></li>
<li><a href="#onmt.Advancer:expand">onmt.Advancer:expand</a></li>
<li><a href="#onmt.Advancer:isComplete">onmt.Advancer:isComplete</a></li>
<li><a href="#onmt.Advancer:setKeptStateIndexes">onmt.Advancer:setKeptStateIndexes</a></li>
<li><a href="#onmt.Advancer:filter">onmt.Advancer:filter</a></li>
</ul>
</li>
              <li><a href="#onmt.translate.Beam.dok">Beam</a><ul>
<li><a href="#onmt.Beam">onmt.Beam</a></li>
<li><a href="#onmt.Beam:getTokens">onmt.Beam:getTokens</a></li>
<li><a href="#onmt.Beam:getState">onmt.Beam:getState</a></li>
<li><a href="#onmt.Beam:getScores">onmt.Beam:getScores</a></li>
<li><a href="#onmt.Beam:getBackPointer">onmt.Beam:getBackPointer</a></li>
<li><a href="#onmt.Beam:getRemaining">onmt.Beam:getRemaining</a></li>
<li><a href="#onmt.Beam:remaining2Orig">onmt.Beam:remaining2Orig</a></li>
<li><a href="#onmt.Beam:orig2Remaining">onmt.Beam:orig2Remaining</a></li>
<li><a href="#onmt.Beam:setState">onmt.Beam:setState</a></li>
<li><a href="#onmt.Beam:setScores">onmt.Beam:setScores</a></li>
<li><a href="#onmt.Beam:setBackPointer">onmt.Beam:setBackPointer</a></li>
</ul>
</li>
              <li><a href="#onmt.translate.BeamSearcher.dok">BeamSearcher</a><ul>
<li><a href="#onmt.BeamSearcher">onmt.BeamSearcher</a></li>
<li><a href="#onmt.BeamSearcher:search">onmt.BeamSearcher:search</a></li>
</ul>
</li>
              <li><a href="#onmt.translate.DecoderAdvancer.dok">DecoderAdvancer</a><ul>
<li><a href="#onmt.DecoderAdvancer">onmt.DecoderAdvancer</a></li>
<li><a href="#onmt.DecoderAdvancer:initBeam">onmt.DecoderAdvancer:initBeam</a></li>
<li><a href="#onmt.DecoderAdvancer:update">onmt.DecoderAdvancer:update</a></li>
<li><a href="#onmt.DecoderAdvancer:expand">onmt.DecoderAdvancer:expand</a></li>
<li><a href="#onmt.DecoderAdvancer:isComplete">onmt.DecoderAdvancer:isComplete</a></li>
<li><a href="#onmt.DecoderAdvancer:filter">onmt.DecoderAdvancer:filter</a></li>
</ul>
</li>
              <li><a href="#onmt.translate.PhraseTable.dok">PhraseTable</a><ul>
<li><a href="#onmt.PhraseTable:lookup">onmt.PhraseTable:lookup</a></li>
<li><a href="#onmt.PhraseTable:contains">onmt.PhraseTable:contains</a></li>
<li><a href="#onmt.PhraseTable">onmt.PhraseTable</a></li>
</ul>
</li>
              <li><a href="#onmt.translate.Translator.dok">Translator</a><ul>
<li><a href="#onmt.Translator:translate">onmt.Translator:translate</a></li>
<li><a href="#onmt.Translator.declareOpts">onmt.Translator.declareOpts</a></li>
<li><a href="#onmt.Translator">onmt.Translator</a></li>
<li><a href="#onmt.Translator:srcFeat">onmt.Translator:srcFeat</a></li>
<li><a href="#onmt.Translator:buildInput">onmt.Translator:buildInput</a></li>
<li><a href="#onmt.Translator:buildInputGold">onmt.Translator:buildInputGold</a></li>
<li><a href="#onmt.Translator:buildOutput">onmt.Translator:buildOutput</a></li>
<li><a href="#onmt.Translator:buildData">onmt.Translator:buildData</a></li>
<li><a href="#onmt.Translator:buildTargetWords">onmt.Translator:buildTargetWords</a></li>
<li><a href="#onmt.Translator:buildTargetFeatures">onmt.Translator:buildTargetFeatures</a></li>
<li><a href="#onmt.Translator:translateBatch">onmt.Translator:translateBatch</a></li>
</ul>
</li>
              <li><a href="#onmt.translate.init.dok">init</a></li>
       </ul>
       </li>
       <li><a href="#onmt.utils.dok">utils</a>
       <ul>
              <li><a href="#onmt.utils.CrayonLogger.dok">CrayonLogger</a></li>
              <li><a href="#onmt.utils.Cuda.dok">Cuda</a><ul>
<li><a href="#onmt.Cuda.getRNGStates">onmt.Cuda.getRNGStates</a></li>
<li><a href="#onmt.Cuda.setRNGStates">onmt.Cuda.setRNGStates</a></li>
<li><a href="#onmt.Cuda.convert">onmt.Cuda.convert</a></li>
<li><a href="#onmt.Cuda.synchronize">onmt.Cuda.synchronize</a></li>
<li><a href="#onmt.Cuda.gpuCount">onmt.Cuda.gpuCount</a></li>
<li><a href="#onmt.Cuda.freeMemory">onmt.Cuda.freeMemory</a></li>
<li><a href="#onmt.Cuda.declareOpts">onmt.Cuda.declareOpts</a></li>
<li><a href="#onmt.Cuda.init">onmt.Cuda.init</a></li>
</ul>
</li>
              <li><a href="#onmt.utils.Dict.dok">Dict</a><ul>
<li><a href="#onmt.Dict:size">onmt.Dict:size</a></li>
<li><a href="#onmt.Dict:loadFile">onmt.Dict:loadFile</a></li>
<li><a href="#onmt.Dict:writeFile">onmt.Dict:writeFile</a></li>
<li><a href="#onmt.Dict:lookup">onmt.Dict:lookup</a></li>
<li><a href="#onmt.Dict:addSpecial">onmt.Dict:addSpecial</a></li>
<li><a href="#onmt.Dict:addSpecials">onmt.Dict:addSpecials</a></li>
<li><a href="#onmt.Dict:add">onmt.Dict:add</a></li>
<li><a href="#onmt.Dict:prune">onmt.Dict:prune</a></li>
<li><a href="#onmt.Dict:pruneByMinFrequency">onmt.Dict:pruneByMinFrequency</a></li>
<li><a href="#onmt.Dict:convertToIdx">onmt.Dict:convertToIdx</a></li>
<li><a href="#onmt.Dict:convertToLabels">onmt.Dict:convertToLabels</a></li>
<li><a href="#onmt.Dict">onmt.Dict</a></li>
</ul>
</li>
              <li><a href="#onmt.utils.ExtendedCmdLine.dok">ExtendedCmdLine</a><ul>
<li><a href="#onmt.ExtendedCmdLine:loadConfig">onmt.ExtendedCmdLine:loadConfig</a></li>
<li><a href="#onmt.ExtendedCmdLine.isInt">onmt.ExtendedCmdLine.isInt</a></li>
<li><a href="#onmt.ExtendedCmdLine.isUInt">onmt.ExtendedCmdLine.isUInt</a></li>
<li><a href="#onmt.ExtendedCmdLine.listUInt">onmt.ExtendedCmdLine.listUInt</a></li>
<li><a href="#onmt.ExtendedCmdLine.isFloat">onmt.ExtendedCmdLine.isFloat</a></li>
<li><a href="#onmt.ExtendedCmdLine.nonEmpty">onmt.ExtendedCmdLine.nonEmpty</a></li>
<li><a href="#onmt.ExtendedCmdLine.fileExists">onmt.ExtendedCmdLine.fileExists</a></li>
<li><a href="#onmt.ExtendedCmdLine.fileNullOrExists">onmt.ExtendedCmdLine.fileNullOrExists</a></li>
<li><a href="#onmt.ExtendedCmdLine.dirStructure">onmt.ExtendedCmdLine.dirStructure</a></li>
<li><a href="#onmt.ExtendedCmdLine">onmt.ExtendedCmdLine</a></li>
<li><a href="#onmt.ExtendedCmdLine:help">onmt.ExtendedCmdLine:help</a></li>
<li><a href="#onmt.ExtendedCmdLine:error">onmt.ExtendedCmdLine:error</a></li>
<li><a href="#onmt.ExtendedCmdLine:option">onmt.ExtendedCmdLine:option</a></li>
<li><a href="#onmt.ExtendedCmdLine:logConfig">onmt.ExtendedCmdLine:logConfig</a></li>
<li><a href="#onmt.ExtendedCmdLine:dumpConfig">onmt.ExtendedCmdLine:dumpConfig</a></li>
<li><a href="#onmt.ExtendedCmdLine:parse">onmt.ExtendedCmdLine:parse</a></li>
<li><a href="#onmt.ExtendedCmdLine:setCmdLineOptions">onmt.ExtendedCmdLine:setCmdLineOptions</a></li>
<li><a href="#onmt.ExtendedCmdLine.getModuleOpts">onmt.ExtendedCmdLine.getModuleOpts</a></li>
<li><a href="#onmt.ExtendedCmdLine.getArgument">onmt.ExtendedCmdLine.getArgument</a></li>
</ul>
</li>
              <li><a href="#onmt.utils.Features.dok">Features</a></li>
              <li><a href="#onmt.utils.FileReader.dok">FileReader</a><ul>
<li><a href="#onmt.FileReader:next">onmt.FileReader:next</a></li>
<li><a href="#onmt.FileReader">onmt.FileReader</a></li>
<li><a href="#onmt.FileReader:close">onmt.FileReader:close</a></li>
</ul>
</li>
              <li><a href="#onmt.utils.Logger.dok">Logger</a><ul>
<li><a href="#onmt.Logger">onmt.Logger</a></li>
<li><a href="#onmt.Logger:log">onmt.Logger:log</a></li>
<li><a href="#onmt.Logger:info">onmt.Logger:info</a></li>
<li><a href="#onmt.Logger:warning">onmt.Logger:warning</a></li>
<li><a href="#onmt.Logger:error">onmt.Logger:error</a></li>
<li><a href="#onmt.Logger:debug">onmt.Logger:debug</a></li>
<li><a href="#onmt.Logger:writeMsg">onmt.Logger:writeMsg</a></li>
<li><a href="#onmt.Logger:setVisibleLevel">onmt.Logger:setVisibleLevel</a></li>
<li><a href="#onmt.Logger:shutDown">onmt.Logger:shutDown</a></li>
<li><a href="#onmt.Logger.declareOpts">onmt.Logger.declareOpts</a></li>
</ul>
</li>
              <li><a href="#onmt.utils.Memory.dok">Memory</a><ul>
<li><a href="#onmt.Memory.optimize">onmt.Memory.optimize</a></li>
<li><a href="#onmt.Memory.declareOpts">onmt.Memory.declareOpts</a></li>
</ul>
</li>
              <li><a href="#onmt.utils.MemoryOptimizer.dok">MemoryOptimizer</a><ul>
<li><a href="#onmt.MemoryOptimizer">onmt.MemoryOptimizer</a></li>
<li><a href="#onmt.MemoryOptimizer:optimize">onmt.MemoryOptimizer:optimize</a></li>
</ul>
</li>
              <li><a href="#onmt.utils.Parallel.dok">Parallel</a><ul>
<li><a href="#onmt.Parallel.launch">onmt.Parallel.launch</a></li>
<li><a href="#onmt.Parallel.accGradParams">onmt.Parallel.accGradParams</a></li>
<li><a href="#onmt.Parallel.updateAndSync">onmt.Parallel.updateAndSync</a></li>
<li><a href="#onmt.Parallel.syncParams">onmt.Parallel.syncParams</a></li>
<li><a href="#onmt.Parallel.getCounter">onmt.Parallel.getCounter</a></li>
<li><a href="#onmt.Parallel.gmutexId">onmt.Parallel.gmutexId</a></li>
<li><a href="#onmt.Parallel.init">onmt.Parallel.init</a></li>
</ul>
</li>
              <li><a href="#onmt.utils.Profiler.dok">Profiler</a><ul>
<li><a href="#onmt.Profiler">onmt.Profiler</a></li>
<li><a href="#onmt.Profiler:reset">onmt.Profiler:reset</a></li>
<li><a href="#onmt.Profiler:start">onmt.Profiler:start</a></li>
<li><a href="#onmt.Profiler:stop">onmt.Profiler:stop</a></li>
<li><a href="#onmt.Profiler:dump">onmt.Profiler:dump</a></li>
<li><a href="#onmt.Profiler:add">onmt.Profiler:add</a></li>
<li><a href="#onmt.Profiler:log">onmt.Profiler:log</a></li>
<li><a href="#onmt.Profiler.declareOpts">onmt.Profiler.declareOpts</a></li>
<li><a href="#onmt.Profiler.addHook">onmt.Profiler.addHook</a></li>
</ul>
</li>
              <li><a href="#onmt.utils.String.dok">String</a></li>
              <li><a href="#onmt.utils.Table.dok">Table</a></li>
              <li><a href="#onmt.utils.Tensor.dok">Tensor</a></li>
              <li><a href="#onmt.utils.init.dok">init</a></li>
       </ul>
       </li>
</ul>
</div>
<section>
<div class='docSection'><a name="onmt.init.dok"></a></div><div class='docSection'><a name="onmt.Constants.dok"></a></div><div class='docSection'><a name="onmt.Factory.dok"></a><p><a name="onmt.Factory.dok"></a></p>

<h2>onmt.Factory</h2>

<h4>Undocumented methods</h4>

<p><a name="onmt.Factory.declareOpts"></a></p>

<ul>
<li><code>onmt.Factory.declareOpts(cmd)</code>
<a name="onmt.Factory.getOutputSizes"></a></li>
<li><code>onmt.Factory.getOutputSizes(dicts)</code>
<a name="onmt.Factory.buildEncoder"></a></li>
<li><code>onmt.Factory.buildEncoder(opt, inputNetwork, verbose)</code>
<a name="onmt.Factory.buildWordEncoder"></a></li>
<li><code>onmt.Factory.buildWordEncoder(opt, dicts, verbose)</code>
<a name="onmt.Factory.loadEncoder"></a></li>
<li><code>onmt.Factory.loadEncoder(pretrained, clone)</code>
<a name="onmt.Factory.buildDecoder"></a></li>
<li><code>onmt.Factory.buildDecoder(opt, inputNetwork, generator, attnModel, verbose)</code>
<a name="onmt.Factory.buildWordDecoder"></a></li>
<li><code>onmt.Factory.buildWordDecoder(opt, dicts, verbose)</code>
<a name="onmt.Factory.loadDecoder"></a></li>
<li><code>onmt.Factory.loadDecoder(pretrained, clone)</code>
<a name="onmt.Factory.buildGenerator"></a></li>
<li><code>onmt.Factory.buildGenerator(rnnSize, dicts)</code>
<a name="onmt.Factory.buildAttention"></a></li>
<li><code>onmt.Factory.buildAttention(args)</code>
<a name="onmt.Factory.loadGenerator"></a></li>
<li><code>onmt.Factory.loadGenerator(pretrained, clone)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.LanguageModel.dok"></a><p><a name="onmt.LanguageModel.dok"></a></p>

<h2>onmt.LanguageModel</h2>

<p>Language Model. 
<a name="onmt.LanguageModel.modelName"></a></p>

<h3>onmt.LanguageModel.modelName()</h3>

<p>Returns model name.
<a name="onmt.LanguageModel.dataType"></a></p>

<h3>onmt.LanguageModel.dataType()</h3>

<p>Returns expected dataMode.</p>

<h4>Undocumented methods</h4>

<p><a name="onmt.LanguageModel.declareOpts"></a></p>

<ul>
<li><code>onmt.LanguageModel.declareOpts(cmd)</code>
<a name="onmt.LanguageModel"></a></li>
<li><code>onmt.LanguageModel(args, dicts, verbose)</code>
<a name="onmt.LanguageModel.load"></a></li>
<li><code>onmt.LanguageModel.load(args, models, dicts, isReplica)</code>
<a name="onmt.LanguageModel:enableProfiling"></a></li>
<li><code>onmt.LanguageModel:enableProfiling()</code>
<a name="onmt.LanguageModel:getOutput"></a></li>
<li><code>onmt.LanguageModel:getOutput(batch)</code>
<a name="onmt.LanguageModel:forwardComputeLoss"></a></li>
<li><code>onmt.LanguageModel:forwardComputeLoss(batch)</code>
<a name="onmt.LanguageModel:trainNetwork"></a></li>
<li><code>onmt.LanguageModel:trainNetwork(batch)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.Model.dok"></a><p><a name="onmt.Model.dok"></a></p>

<h2>onmt.Model</h2>

<p>Generic Model class. 
<a name="onmt.Model:changeParameters"></a></p>

<h3>onmt.Model:changeParameters(changes)</h3>

<p>Dynamically change parameters in the graph.</p>

<h4>Undocumented methods</h4>

<p><a name="onmt.Model.declareOpts"></a></p>

<ul>
<li><code>onmt.Model.declareOpts(cmd)</code>
<a name="onmt.Model"></a></li>
<li><code>onmt.Model(args)</code>
<a name="onmt.Model:getInputLabelsCount"></a></li>
<li><code>onmt.Model:getInputLabelsCount(batch)</code>
<a name="onmt.Model:getOutputLabelsCount"></a></li>
<li><code>onmt.Model:getOutputLabelsCount(batch)</code>
<a name="onmt.Model:evaluate"></a></li>
<li><code>onmt.Model:evaluate()</code>
<a name="onmt.Model:training"></a></li>
<li><code>onmt.Model:training()</code>
<a name="onmt.Model:initParams"></a></li>
<li><code>onmt.Model:initParams(verbose)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.ModelSelector.dok"></a></div><div class='docSection'><a name="onmt.Seq2Seq.dok"></a><p><a name="onmt.Seq2Seq.dok"></a></p>

<h2>onmt.Seq2Seq</h2>

<p>Sequence to sequence model with attention. 
<a name="onmt.Seq2Seq.modelName"></a></p>

<h3>onmt.Seq2Seq.modelName()</h3>

<p>Returns model name.
<a name="onmt.Seq2Seq.dataType"></a></p>

<h3>onmt.Seq2Seq.dataType()</h3>

<p>Returns expected dataMode.</p>

<h4>Undocumented methods</h4>

<p><a name="onmt.Seq2Seq.declareOpts"></a></p>

<ul>
<li><code>onmt.Seq2Seq.declareOpts(cmd)</code>
<a name="onmt.Seq2Seq"></a></li>
<li><code>onmt.Seq2Seq(args, dicts, verbose)</code>
<a name="onmt.Seq2Seq.load"></a></li>
<li><code>onmt.Seq2Seq.load(args, models, dicts, isReplica)</code>
<a name="onmt.Seq2Seq:returnIndividualLosses"></a></li>
<li><code>onmt.Seq2Seq:returnIndividualLosses(enable)</code>
<a name="onmt.Seq2Seq:enableProfiling"></a></li>
<li><code>onmt.Seq2Seq:enableProfiling()</code>
<a name="onmt.Seq2Seq:getOutput"></a></li>
<li><code>onmt.Seq2Seq:getOutput(batch)</code>
<a name="onmt.Seq2Seq:maskPadding"></a></li>
<li><code>onmt.Seq2Seq:maskPadding(batch)</code>
<a name="onmt.Seq2Seq:forwardComputeLoss"></a></li>
<li><code>onmt.Seq2Seq:forwardComputeLoss(batch)</code>
<a name="onmt.Seq2Seq:trainNetwork"></a></li>
<li><code>onmt.Seq2Seq:trainNetwork(batch, dryRun)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.SeqTagger.dok"></a><p><a name="onmt.SeqTagger.dok"></a></p>

<h2>onmt.SeqTagger</h2>

<p>Sequence to sequence model with attention. 
<a name="onmt.SeqTagger.modelName"></a></p>

<h3>onmt.SeqTagger.modelName()</h3>

<p>Returns model name.
<a name="onmt.SeqTagger.dataType"></a></p>

<h3>onmt.SeqTagger.dataType()</h3>

<p>Returns expected dataMode</p>

<h4>Undocumented methods</h4>

<p><a name="onmt.SeqTagger.declareOpts"></a></p>

<ul>
<li><code>onmt.SeqTagger.declareOpts(cmd)</code>
<a name="onmt.SeqTagger"></a></li>
<li><code>onmt.SeqTagger(args, dicts, verbose)</code>
<a name="onmt.SeqTagger.load"></a></li>
<li><code>onmt.SeqTagger.load(args, models, dicts, isReplica)</code>
<a name="onmt.SeqTagger:enableProfiling"></a></li>
<li><code>onmt.SeqTagger:enableProfiling()</code>
<a name="onmt.SeqTagger:getOutput"></a></li>
<li><code>onmt.SeqTagger:getOutput(batch)</code>
<a name="onmt.SeqTagger:forwardComputeLoss"></a></li>
<li><code>onmt.SeqTagger:forwardComputeLoss(batch)</code>
<a name="onmt.SeqTagger:trainNetwork"></a></li>
<li><code>onmt.SeqTagger:trainNetwork(batch)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.data.AliasMultinomial.dok"></a><h3>AliasMultinomial.lua</h3>

<p>Copied with small adjustments from:
    <a href="https://github.com/nicholas-leonard/torchx/blob/master/AliasMultinomial.lua">https://github.com/nicholas-leonard/torchx/blob/master/AliasMultinomial.lua</a> (7eeb6ae)</p>

<p><a name="onmt.AliasMultinomial.dok"></a></p>

<h2>onmt.AliasMultinomial</h2>

<p>ref.: <a href="https://hips.seas.harvard.edu/blog/2013/03/03/the-alias-method-efficient-sampling-with-many-discrete-outcomes/">https://hips.seas.harvard.edu/blog/2013/03/03/the-alias-method-efficient-sampling-with-many-discrete-outcomes/</a></p>

<h4>Undocumented methods</h4>

<p><a name="onmt.AM"></a></p>

<ul>
<li><code>onmt.AM(probs)</code>
<a name="onmt.AM:setup"></a></li>
<li><code>onmt.AM:setup(probs)</code>
<a name="onmt.AM:draw"></a></li>
<li><code>onmt.AM:draw()</code>
<a name="onmt.AM:batchdraw"></a></li>
<li><code>onmt.AM:batchdraw(output)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.data.Batch.dok"></a><p><a name="onmt.Batch.dok"></a></p>

<h2>onmt.Batch</h2>

<p>A batch of sentences to translate and targets. Manages padding,
  features, and batch alignment (for efficiency).</p>

<p>Used by the decoder and encoder objects.</p>

<p><a name="onmt.Batch"></a></p>

<h3>onmt.Batch(src, srcFeatures, tgt, tgtFeatures)</h3>

<p>Create a batch object.</p>

<p>Parameters:</p>

<ul>
<li><code>src</code> - 2D table of source batch indices or prebuilt source batch vectors</li>
<li><code>srcFeatures</code> - 2D table of source batch features (opt)</li>
<li><code>tgt</code> - 2D table of target batch indices</li>
<li><code>tgtFeatures</code> - 2D table of target batch features (opt)</li>
</ul>

<p><a name="onmt.Batch:setSourceInput"></a></p>

<h3>onmt.Batch:setSourceInput(sourceInput)</h3>

<p>Set source input directly,</p>

<p>Parameters:</p>

<ul>
<li><code>sourceInput</code> - a Tensor of size (sequence_length, batch_size, feature_dim)
,or a sequence of size (sequence_length, batch_size). Be aware that sourceInput is not cloned here.</li>
</ul>

<p><a name="onmt.Batch:setTargetInput"></a></p>

<h3>onmt.Batch:setTargetInput(targetInput)</h3>

<p>Set target input directly.</p>

<p>Parameters:</p>

<ul>
<li><code>targetInput</code> - a tensor of size (sequence_length, batch_size). Padded with onmt.Constants.PAD. Be aware that targetInput is not cloned here.</li>
</ul>

<p><a name="onmt.Batch:setTargetOutput"></a></p>

<h3>onmt.Batch:setTargetOutput(targetOutput)</h3>

<p>Set target output directly.</p>

<p>Parameters:</p>

<ul>
<li><code>targetOutput</code> - a tensor of size (sequence_length, batch_size). Padded with onmt.Constants.PAD.  Be aware that targetOutput is not cloned here.</li>
</ul>

<p><a name="onmt.Batch:getSourceInput"></a></p>

<h3>onmt.Batch:getSourceInput(t)</h3>

<p>Get source input batch at timestep <code>t</code>. 
<a name="onmt.Batch:getTargetInput"></a></p>

<h3>onmt.Batch:getTargetInput(t)</h3>

<p>Get target input batch at timestep <code>t</code>. 
<a name="onmt.Batch:getTargetOutput"></a></p>

<h3>onmt.Batch:getTargetOutput(t)</h3>

<p>Get target output batch at timestep <code>t</code> (values t+1). </p>
</div><div class='docSection'><a name="onmt.data.BatchTensor.dok"></a><p><a name="onmt.BatchTensor.dok"></a></p>

<h2>onmt.BatchTensor</h2>

<p><a name="onmt.BatchTensor"></a></p>

<h3>onmt.BatchTensor(T, sizes)</h3>

<p>Take Batch x TimeStep x layer size tensors</p>

<h4>Undocumented methods</h4>

<p><a name="onmt.BatchTensor:getSourceInput"></a></p>

<ul>
<li><code>onmt.BatchTensor:getSourceInput(t)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.data.Dataset.dok"></a><p><a name="onmt.Dataset.dok"></a></p>

<h2>onmt.Dataset</h2>

<p>Data management and batch creation. Handles data created by <code>preprocess.lua</code>. 
<a name="onmt.Dataset"></a></p>

<h3>onmt.Dataset(srcData, tgtData)</h3>

<p>Initialize a data object given aligned tables of IntTensors <code>srcData</code>
  and <code>tgtData</code>.</p>

<p><a name="onmt.Dataset:setBatchSize"></a></p>

<h3>onmt.Dataset:setBatchSize(maxBatchSize, uneven_batches)</h3>

<p>Setup up the training data to respect <code>maxBatchSize</code>.
     If uneven_batches - then build up batches with different lengths 
<a name="onmt.Dataset:batchCount"></a></p>

<h3>onmt.Dataset:batchCount()</h3>

<p>Return number of batches. 
<a name="onmt.Dataset:getBatch"></a></p>

<h3>onmt.Dataset:getBatch(idx)</h3>

<p>Get <code>Batch</code> number <code>idx</code>. If nil make a batch of all the data. </p>
</div><div class='docSection'><a name="onmt.data.Preprocessor.dok"></a><h3>Preprocessor.lua</h3>

<p>Data Preparation functions.</p>

<p><a name="onmt.Preprocessor.dok"></a></p>

<h2>onmt.Preprocessor</h2>

<h4>Undocumented methods</h4>

<p><a name="onmt.Preprocessor.declareOpts"></a></p>

<ul>
<li><code>onmt.Preprocessor.declareOpts(cmd, mode)</code>
<a name="onmt.Preprocessor"></a></li>
<li><code>onmt.Preprocessor(args, mode)</code>
<a name="onmt.Preprocessor:makeBilingualData"></a></li>
<li><code>onmt.Preprocessor:makeBilingualData(srcFile, tgtFile, srcDicts, tgtDicts, isValid)</code>
<a name="onmt.Preprocessor:makeFeatTextData"></a></li>
<li><code>onmt.Preprocessor:makeFeatTextData(srcFile, tgtFile, tgtDicts, isValid)</code>
<a name="onmt.Preprocessor:makeMonolingualData"></a></li>
<li><code>onmt.Preprocessor:makeMonolingualData(file, dicts, isValid)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.data.SampledDataset.dok"></a><h3>SampledDataset.lua</h3>

<p>Data management and batch creation. Handles data created by <code>preprocess.lua</code>.</p>

<p><a name="onmt.SampledDataset.dok"></a></p>

<h2>onmt.SampledDataset</h2>

<p><a name="onmt.SampledDataset"></a></p>

<h3>onmt.SampledDataset(srcData, tgtData, opt)</h3>

<p>Initialize a data object given aligned tables of IntTensors <code>srcData</code>
  and <code>tgtData</code>.</p>

<p><a name="onmt.SampledDataset:sample"></a></p>

<h3>onmt.SampledDataset:sample(logLevel)</h3>

<p>Initiate sampling. 
<a name="onmt.SampledDataset:getPpl"></a></p>

<h3>onmt.SampledDataset:getPpl()</h3>

<p>Get perplexity. 
<a name="onmt.SampledDataset:setLoss"></a></p>

<h3>onmt.SampledDataset:setLoss(batchIdx, loss)</h3>

<p>Set perplexity. 
<a name="onmt.SampledDataset:setBatchSize"></a></p>

<h3>onmt.SampledDataset:setBatchSize(maxBatchSize, uneven_batches)</h3>

<p>Setup up the training data to respect <code>maxBatchSize</code>. 
<a name="onmt.SampledDataset:getNumSampled"></a></p>

<h3>onmt.SampledDataset:getNumSampled()</h3>

<p>Return number of sampled instances. 
<a name="onmt.SampledDataset:batchCount"></a></p>

<h3>onmt.SampledDataset:batchCount()</h3>

<p>Return number of batches. 
<a name="onmt.SampledDataset:getBatch"></a></p>

<h3>onmt.SampledDataset:getBatch(batchIdx)</h3>

<p>Get <code>Batch</code> number <code>idx</code>. If nil make a batch of all the data. </p>

<h4>Undocumented methods</h4>

<p><a name="onmt.SampledDataset.declareOpts"></a></p>

<ul>
<li><code>onmt.SampledDataset.declareOpts(cmd)</code>
<a name="onmt.SampledDataset:checkModel"></a></li>
<li><code>onmt.SampledDataset:checkModel(model)</code>
<a name="onmt.SampledDataset:needIndividualLosses"></a></li>
<li><code>onmt.SampledDataset:needIndividualLosses()</code></li>
</ul>
</div><div class='docSection'><a name="onmt.data.Vocabulary.dok"></a><p><a name="onmt.Vocabulary.dok"></a></p>

<h2>onmt.Vocabulary</h2>

<p>Vocabulary management utility functions. </p>

<h4>Undocumented methods</h4>

<p><a name="onmt.Vocabulary.make"></a></p>

<ul>
<li><code>onmt.Vocabulary.make(filename, validFunc, idxFile)</code>
<a name="onmt.Vocabulary.init"></a></li>
<li><code>onmt.Vocabulary.init(name, dataFile, vocabFile, vocabSize, wordsMinFrequency, featuresVocabsFiles, validFunc, idxFile)</code>
<a name="onmt.Vocabulary.save"></a></li>
<li><code>onmt.Vocabulary.save(name, vocab, file)</code>
<a name="onmt.Vocabulary.saveFeatures"></a></li>
<li><code>onmt.Vocabulary.saveFeatures(name, vocabs, prefix)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.data.init.dok"></a></div><div class='docSection'><a name="onmt.modules.BiEncoder.dok"></a><p><a name="onmt.BiEncoder.dok"></a></p>

<h2>onmt.BiEncoder</h2>

<p>BiEncoder is a bidirectional Sequencer used for the source language.</p>

<p><code>netFwd</code></p>

<pre><code>h_1 =&gt; h_2 =&gt; h_3 =&gt; ... =&gt; h_n
 |      |      |             |
 .      .      .             .
 |      |      |             |
h_1 =&gt; h_2 =&gt; h_3 =&gt; ... =&gt; h_n
 |      |      |             |
 |      |      |             |
x_1    x_2    x_3           x_n
</code></pre>

<p><code>netBwd</code></p>

<pre><code>h_1 &lt;= h_2 &lt;= h_3 &lt;= ... &lt;= h_n
 |      |      |             |
 .      .      .             .
 |      |      |             |
h_1 &lt;= h_2 &lt;= h_3 &lt;= ... &lt;= h_n
 |      |      |             |
 |      |      |             |
x_1    x_2    x_3           x_n
</code></pre>

<p>Inherits from <a href="onmt+modules+Sequencer">onmt.Sequencer</a>.</p>

<p><a name="onmt.BiEncoder"></a></p>

<h3>onmt.BiEncoder(args, input)</h3>

<p>Create a bi-encoder.</p>

<p>Parameters:</p>

<ul>
<li><code>input</code> - input neural network.</li>
<li><code>rnn</code> - recurrent template module.</li>
<li><code>merge</code> - fwd/bwd merge operation {&quot;concat&quot;, &quot;sum&quot;}</li>
</ul>

<p><a name="onmt.BiEncoder.load"></a></p>

<h3>onmt.BiEncoder.load(pretrained)</h3>

<p>Return a new BiEncoder using the serialized data <code>pretrained</code>. 
<a name="onmt.BiEncoder:serialize"></a></p>

<h3>onmt.BiEncoder:serialize()</h3>

<p>Return data to serialize. 
<a name="onmt.BiEncoder:contextSize"></a></p>

<h3>onmt.BiEncoder:contextSize(sourceSize, sourceLength)</h3>

<p>size of context vector</p>

<h4>Undocumented methods</h4>

<p><a name="onmt.BiEncoder.declareOpts"></a></p>

<ul>
<li><code>onmt.BiEncoder.declareOpts(cmd)</code>
<a name="onmt.BiEncoder:resetPreallocation"></a></li>
<li><code>onmt.BiEncoder:resetPreallocation()</code>
<a name="onmt.BiEncoder:maskPadding"></a></li>
<li><code>onmt.BiEncoder:maskPadding()</code>
<a name="onmt.BiEncoder:forward"></a></li>
<li><code>onmt.BiEncoder:forward(batch)</code>
<a name="onmt.BiEncoder:backward"></a></li>
<li><code>onmt.BiEncoder:backward(batch, gradStatesOutput, gradContextOutput)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.modules.DBiEncoder.dok"></a><p><a name="onmt.DBiEncoder.dok"></a></p>

<h2>onmt.DBiEncoder</h2>

<p>DBiEncoder is a deep bidirectional Sequencer used for the source language.</p>

<p><a name="onmt.DBiEncoder"></a></p>

<h3>onmt.DBiEncoder(args, input)</h3>

<p>Create a deep bidirectional encoder - each layers reconnect before starting another bidirectional layer</p>

<p>Parameters:</p>

<ul>
<li><code>args</code> - global arguments</li>
<li><code>input</code> - input neural network.</li>
</ul>

<p><a name="onmt.DBiEncoder.load"></a></p>

<h3>onmt.DBiEncoder.load(pretrained)</h3>

<p>Return a new DBiEncoder using the serialized data <code>pretrained</code>. 
<a name="onmt.DBiEncoder:serialize"></a></p>

<h3>onmt.DBiEncoder:serialize()</h3>

<p>Return data to serialize. 
<a name="onmt.DBiEncoder:contextSize"></a></p>

<h3>onmt.DBiEncoder:contextSize(sourceSize, sourceLength)</h3>

<p>size of context vector</p>

<h4>Undocumented methods</h4>

<p><a name="onmt.DBiEncoder.declareOpts"></a></p>

<ul>
<li><code>onmt.DBiEncoder.declareOpts(cmd)</code>
<a name="onmt.DBiEncoder:resetPreallocation"></a></li>
<li><code>onmt.DBiEncoder:resetPreallocation()</code>
<a name="onmt.DBiEncoder:maskPadding"></a></li>
<li><code>onmt.DBiEncoder:maskPadding()</code>
<a name="onmt.DBiEncoder:forward"></a></li>
<li><code>onmt.DBiEncoder:forward(batch)</code>
<a name="onmt.DBiEncoder:backward"></a></li>
<li><code>onmt.DBiEncoder:backward(batch, gradStatesOutput, gradContextOutput)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.modules.Decoder.dok"></a><p><a name="onmt.Decoder.dok"></a></p>

<h2>onmt.Decoder</h2>

<p>Unit to decode a sequence of output tokens.</p>

<pre><code> .      .      .             .
 |      |      |             |
h_1 =&gt; h_2 =&gt; h_3 =&gt; ... =&gt; h_n
 |      |      |             |
 .      .      .             .
 |      |      |             |
h_1 =&gt; h_2 =&gt; h_3 =&gt; ... =&gt; h_n
 |      |      |             |
 |      |      |             |
x_1    x_2    x_3           x_n
</code></pre>

<p>Inherits from <a href="onmt+modules+Sequencer">onmt.Sequencer</a>.</p>

<p><a name="onmt.Decoder"></a></p>

<h3>onmt.Decoder(args, inputNetwork, generator, attentionModel)</h3>

<p>Construct a decoder layer.</p>

<p>Parameters:</p>

<ul>
<li><code>args</code> - module arguments</li>
<li><code>inputNetwork</code> - input nn module.</li>
<li><code>generator</code> - an output generator.</li>
<li><code>attentionModel</code> - attention model to apply on source.</li>
</ul>

<p><a name="onmt.Decoder.load"></a></p>

<h3>onmt.Decoder.load(pretrained)</h3>

<p>Return a new Decoder using the serialized data <code>pretrained</code>. 
<a name="onmt.Decoder:serialize"></a></p>

<h3>onmt.Decoder:serialize()</h3>

<p>Return data to serialize. 
<a name="onmt.Decoder:maskPadding"></a></p>

<h3>onmt.Decoder:maskPadding(sourceSizes, sourceLength)</h3>

<p>Mask padding means that the attention-layer is constrained to
  give zero-weight to padding. This is done by storing a reference
  to the softmax attention-layer.</p>

<p>Parameters:</p>

<ul>
<li>See  <a href="onmt+modules+MaskedSoftmax">onmt.MaskedSoftmax</a>.</li>
</ul>

<p><a name="onmt.Decoder:forwardOne"></a></p>

<h3>onmt.Decoder:forwardOne(input, prevStates, context, prevOut, t)</h3>

<p>Run one step of the decoder.</p>

<p>Parameters:</p>

<ul>
<li><code>input</code> - input to be passed to inputNetwork.</li>
<li><code>prevStates</code> - stack of hidden states (batch x layers*model x rnnSize)</li>
<li><code>context</code> - encoder output (batch x n x rnnSize)</li>
<li><code>prevOut</code> - previous distribution (batch x #words)</li>
<li><code>t</code> - current timestep</li>
</ul>

<p>Returns:</p>

<ol>
<li><code>out</code> - Top-layer hidden state.</li>
<li><code>states</code> - All states.</li>
</ol>

<p><a name="onmt.Decoder:forward"></a></p>

<h3>onmt.Decoder:forward(batch, encoderStates, context)</h3>

<p>Compute all forward steps.</p>

<p>Parameters:</p>

<ul>
<li><code>batch</code> - a <code>Batch</code> object.</li>
<li><code>encoderStates</code> - a batch of initial decoder states (optional) [0]</li>
<li><p><code>context</code> - the context to apply attention to.</p>

<p>Returns: Table of top hidden state for each timestep.</p></li>
</ul>

<p><a name="onmt.Decoder:backward"></a></p>

<h3>onmt.Decoder:backward(batch, outputs, criterion)</h3>

<p>Compute the backward update.</p>

<p>Parameters:</p>

<ul>
<li><code>batch</code> - a <code>Batch</code> object</li>
<li><code>outputs</code> - expected outputs</li>
<li><p><code>criterion</code> - a single target criterion object</p>

<p>Note: This code runs both the standard backward and criterion forward/backward.</p>

<h2>It returns both the gradInputs and the loss.</h2>

<p><a name="onmt.Decoder:computeLoss"></a></p></li>
</ul>

<h3>onmt.Decoder:computeLoss(batch, encoderStates, context, criterion)</h3>

<p>Compute the loss on a batch.</p>

<p>Parameters:</p>

<ul>
<li><code>batch</code> - a <code>Batch</code> to score.</li>
<li><code>encoderStates</code> - initialization of decoder.</li>
<li><code>context</code> - the attention context.</li>
<li><code>criterion</code> - a pointwise criterion.</li>
</ul>

<p><a name="onmt.Decoder:computeScore"></a></p>

<h3>onmt.Decoder:computeScore(batch, encoderStates, context)</h3>

<p>Compute the score of a batch.</p>

<p>Parameters:</p>

<ul>
<li><code>batch</code> - a <code>Batch</code> to score.</li>
<li><code>encoderStates</code> - initialization of decoder.</li>
<li><code>context</code> - the attention context.</li>
</ul>

<h4>Undocumented methods</h4>

<p><a name="onmt.Decoder.declareOpts"></a></p>

<ul>
<li><code>onmt.Decoder.declareOpts(cmd)</code>
<a name="onmt.Decoder:returnIndividualLosses"></a></li>
<li><code>onmt.Decoder:returnIndividualLosses(enable)</code>
<a name="onmt.Decoder:resetPreallocation"></a></li>
<li><code>onmt.Decoder:resetPreallocation()</code>
<a name="onmt.Decoder:findAttentionModel"></a></li>
<li><code>onmt.Decoder:findAttentionModel()</code>
<a name="onmt.Decoder:forwardAndApply"></a></li>
<li><code>onmt.Decoder:forwardAndApply(batch, encoderStates, context, func)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.modules.Encoder.dok"></a><p><a name="onmt.Encoder.dok"></a></p>

<h2>onmt.Encoder</h2>

<p>Encoder is a unidirectional Sequencer used for the source language.</p>

<pre><code>h_1 =&gt; h_2 =&gt; h_3 =&gt; ... =&gt; h_n
 |      |      |             |
 .      .      .             .
 |      |      |             |
h_1 =&gt; h_2 =&gt; h_3 =&gt; ... =&gt; h_n
 |      |      |             |
 |      |      |             |
x_1    x_2    x_3           x_n
</code></pre>

<p>Inherits from <a href="onmt+modules+Sequencer">onmt.Sequencer</a>.</p>

<p><a name="onmt.Encoder"></a></p>

<h3>onmt.Encoder(args, inputNetwork)</h3>

<p>Construct an Encoder layer.</p>

<p>Parameters:</p>

<ul>
<li><code>inputNetwork</code> - input module.</li>
<li><code>rnn</code> - recurrent module.</li>
</ul>

<p><a name="onmt.Encoder.load"></a></p>

<h3>onmt.Encoder.load(pretrained)</h3>

<p>Return a new Encoder using the serialized data <code>pretrained</code>. 
<a name="onmt.Encoder:serialize"></a></p>

<h3>onmt.Encoder:serialize()</h3>

<p>Return data to serialize. 
<a name="onmt.Encoder:contextSize"></a></p>

<h3>onmt.Encoder:contextSize(sourceSize, sourceLength)</h3>

<p>size of context vector
<a name="onmt.Encoder:forward"></a></p>

<h3>onmt.Encoder:forward(batch)</h3>

<p>Compute the context representation of an input.</p>

<p>Parameters:</p>

<ul>
<li><code>batch</code> - as defined in batch.lua.</li>
</ul>

<p>Returns:</p>

<ol>
<li>- final hidden states</li>
<li>- context matrix H</li>
</ol>

<p><a name="onmt.Encoder:backward"></a></p>

<h3>onmt.Encoder:backward(batch, gradStatesOutput, gradContextOutput)</h3>

<p>Backward pass (only called during training)</p>

<p>Parameters:</p>

<ul>
<li><code>batch</code> - must be same as for forward</li>
<li><code>gradStatesOutput</code> gradient of loss wrt last state - this can be null if states are not used</li>
<li><p><code>gradContextOutput</code> - gradient of loss wrt full context.</p>

<p>Returns: <code>gradInputs</code> of input network.</p></li>
</ul>

<h4>Undocumented methods</h4>

<p><a name="onmt.Encoder.declareOpts"></a></p>

<ul>
<li><code>onmt.Encoder.declareOpts(cmd)</code>
<a name="onmt.Encoder:resetPreallocation"></a></li>
<li><code>onmt.Encoder:resetPreallocation()</code>
<a name="onmt.Encoder:maskPadding"></a></li>
<li><code>onmt.Encoder:maskPadding()</code></li>
</ul>
</div><div class='docSection'><a name="onmt.modules.FeaturesEmbedding.dok"></a><p><a name="onmt.FeaturesEmbedding.dok"></a></p>

<h2>onmt.FeaturesEmbedding</h2>

<p>A nngraph unit that maps features ids to embeddings. When using multiple
  features this can be the concatenation or the sum of each individual embedding.</p>

<h4>Undocumented methods</h4>

<p><a name="onmt.FeaturesEmbedding"></a></p>

<ul>
<li><code>onmt.FeaturesEmbedding(vocabSizes, vecSizes, merge)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.modules.FeaturesGenerator.dok"></a><p><a name="onmt.FeaturesGenerator.dok"></a></p>

<h2>onmt.FeaturesGenerator</h2>

<p>Feature decoder generator. Given RNN state, produce categorical distribution over
tokens and features.</p>

<p>Implements $$[softmax(W<sup>1</sup> h + b<sup>1),</sup> softmax(W<sup>2</sup> h + b<sup>2),</sup> ..., softmax(W<sup>n</sup> h + b<sup>n)]</sup> $$.</p>

<p><a name="onmt.FeaturesGenerator"></a></p>

<h3>onmt.FeaturesGenerator(rnnSize, outputSizes)</h3>

<p>Parameters:</p>

<ul>
<li><code>rnnSize</code> - Input rnn size.</li>
<li><code>outputSizes</code> - Table of each output size.</li>
</ul>
</div><div class='docSection'><a name="onmt.modules.GRU.dok"></a><p><a name="onmt.GRU.dok"></a></p>

<h2>onmt.GRU</h2>

<p>Implementation of a single stacked-GRU step as
an nn unit.</p>

<pre><code>  h^L_{t-1} --- h^L_t
             |


             .
             |
         [dropout]
             |
  h^1_{t-1} --- h^1_t
             |
             |
            x_t
</code></pre>

<p>Computes $$(h_{t-1}, x_t) =&gt; (h_{t})$$.</p>

<p><a name="onmt.GRU"></a></p>

<h3>onmt.GRU(layers, inputSize, hiddenSize, dropout, residual, dropout_input)</h3>

<p>Parameters:</p>

<ul>
<li><code>layers</code> - Number of layers</li>
<li><code>inputSize</code> - Size of input layer</li>
<li><code>hiddenSize</code> - Size of the hidden layers</li>
<li><code>dropout</code> - Dropout rate to use (in $$[0,1]$$ range).</li>
<li><code>residual</code> - Residual connections between layers (boolean)</li>
<li><code>dropout_input</code> - if true, add a dropout layer on the first layer (useful for instance in complex encoders)</li>
</ul>
</div><div class='docSection'><a name="onmt.modules.Generator.dok"></a><p><a name="onmt.Generator.dok"></a></p>

<h2>onmt.Generator</h2>

<p>Default decoder generator. Given RNN state, produce categorical distribution.</p>

<p>Simply implements $$softmax(W h + b)$$.</p>

<h4>Undocumented methods</h4>

<p><a name="onmt.Generator"></a></p>

<ul>
<li><code>onmt.Generator(rnnSize, outputSize)</code>
<a name="onmt.Generator:updateOutput"></a></li>
<li><code>onmt.Generator:updateOutput(input)</code>
<a name="onmt.Generator:updateGradInput"></a></li>
<li><code>onmt.Generator:updateGradInput(input, gradOutput)</code>
<a name="onmt.Generator:accGradParameters"></a></li>
<li><code>onmt.Generator:accGradParameters(input, gradOutput, scale)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.modules.GlobalAttention.dok"></a><p><a name="onmt.GlobalAttention.dok"></a></p>

<h2>onmt.GlobalAttention</h2>

<p>Global attention takes a matrix and a query vector. It
then computes a parameterized convex combination of the matrix
based on the input query.</p>

<pre><code>H_1 H_2 H_3 ... H_n
 q   q   q       q
  |  |   |       |
   \ |   |      /
       .....
     \   |  /
         a
</code></pre>

<p>Constructs a unit mapping:
  $$(H_1 .. H_n, q) =&gt; (a)$$
  Where H is of <code>batch x n x dim</code> and q is of <code>batch x dim</code>.</p>

<p>The full function is  $$\tanh(W_2 [(softmax((W_1 q + b_1) H) H), q] + b_2)$$.</p>

<ul>
<li>dot: $$score(h_t,{\overline{h}}_s) = h_t<sup>T{\overline{h}}_s$$</sup></li>
<li>general: $$score(h_t,{\overline{h}}_s) = h_t<sup>T</sup> W_a {\overline{h}}_s$$</li>
<li>concat: $$score(h_t,{\overline{h}}_s) = \nu_a<sup>T</sup> tanh(W_a[h_t;{\overline{h}}_s])$$</li>
</ul>

<p><a name="onmt.GlobalAttention"></a></p>

<h3>onmt.GlobalAttention(opt, dim)</h3>

<p>A nn-style module computing attention.</p>

<p>Parameters:</p>

<ul>
<li><code>dim</code> - dimension of the context vectors.</li>
</ul>

<h4>Undocumented methods</h4>

<p><a name="onmt.GlobalAttention.declareOpts"></a></p>

<ul>
<li><code>onmt.GlobalAttention.declareOpts(cmd)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.modules.JoinReplicateTable.dok"></a><p><a name="onmt.JoinReplicateTable.dok"></a></p>

<h2>onmt.JoinReplicateTable</h2>

<h4>Undocumented methods</h4>

<p><a name="onmt.JoinReplicateTable"></a></p>

<ul>
<li><code>onmt.JoinReplicateTable(dimensionReplicate, dimensionJoin, nInputDims)</code>
<a name="onmt.JoinReplicateTable:updateOutput"></a></li>
<li><code>onmt.JoinReplicateTable:updateOutput(input)</code>
<a name="onmt.JoinReplicateTable:updateGradInput"></a></li>
<li><code>onmt.JoinReplicateTable:updateGradInput(input, gradOutput)</code>
<a name="onmt.JoinReplicateTable:type"></a></li>
<li><code>onmt.JoinReplicateTable:type(type, tensorCache)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.modules.LSTM.dok"></a><p><a name="onmt.LSTM.dok"></a></p>

<h2>onmt.LSTM</h2>

<p>Implementation of a single stacked-LSTM step as
an nn unit.</p>

<pre><code>  h^L_{t-1} --- h^L_t
  c^L_{t-1} --- c^L_t
             |


             .
             |
         [dropout]
             |
  h^1_{t-1} --- h^1_t
  c^1_{t-1} --- c^1_t
             |
             |
            x_t
</code></pre>

<p>Computes $$(c_{t-1}, h_{t-1}, x_t) =&gt; (c_{t}, h_{t})$$.</p>

<p><a name="onmt.LSTM"></a></p>

<h3>onmt.LSTM(layers, inputSize, hiddenSize, dropout, residual, dropout_input)</h3>

<p>Parameters:</p>

<ul>
<li><code>layers</code> - Number of LSTM layers, L.</li>
<li><code>inputSize</code> - Size of input layer</li>
<li><code>hiddenSize</code> - Size of the hidden layers.</li>
<li><code>dropout</code> - Dropout rate to use (in $$[0,1]$$ range).</li>
<li><code>residual</code> - Residual connections between layers.</li>
<li><code>dropout_input</code> - if true, add a dropout layer on the first layer (useful for instance in complex encoders)</li>
</ul>
</div><div class='docSection'><a name="onmt.modules.MaskedSoftmax.dok"></a><p><a name="onmt.MaskedSoftmax.dok"></a></p>

<h2>onmt.MaskedSoftmax</h2>

<p>A batched-softmax wrapper to mask the probabilities of padding.</p>

<p>For instance there may be a batch of instances where A is padding.</p>

<pre><code>AAXXXX
AAAAXX
XXXXXX
</code></pre>

<p>MaskedSoftmax ensures that no probability is given to the A&#39;s.</p>

<p>For this example, <code>sourceSizes</code> is {4, 2, 6} and <code>sourceLength</code> is 6.</p>

<p><a name="onmt.MaskedSoftmax"></a></p>

<h3>onmt.MaskedSoftmax(sourceSizes, sourceLength)</h3>

<p>A nn-style module that applies a softmax on input that gives no weight to the left padding.</p>

<p>Parameters:</p>

<ul>
<li><code>sourceSizes</code> -  the true lengths (with left padding).</li>
<li><code>sourceLength</code> - the length of the batch.</li>
</ul>
</div><div class='docSection'><a name="onmt.modules.Network.dok"></a><p><a name="onmt.Network.dok"></a></p>

<h2>onmt.Network</h2>

<p>Wrapper around a single network. </p>

<h4>Undocumented methods</h4>

<p><a name="onmt.Network"></a></p>

<ul>
<li><code>onmt.Network(net)</code>
<a name="onmt.Network:updateOutput"></a></li>
<li><code>onmt.Network:updateOutput(input)</code>
<a name="onmt.Network:updateGradInput"></a></li>
<li><code>onmt.Network:updateGradInput(input, gradOutput)</code>
<a name="onmt.Network:accGradParameters"></a></li>
<li><code>onmt.Network:accGradParameters(input, gradOutput, scale)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.modules.NoAttention.dok"></a><p><a name="onmt.NoAttention.dok"></a></p>

<h2>onmt.NoAttention</h2>

<p>No attention module</p>

<p><a name="onmt.NoAttention"></a></p>

<h3>onmt.NoAttention(_, dim)</h3>

<p>A nn-style module computing attention.</p>

<p>Parameters:</p>

<ul>
<li><code>dim</code> - dimension of the context vectors.</li>
</ul>
</div><div class='docSection'><a name="onmt.modules.PDBiEncoder.dok"></a><p><a name="onmt.PDBiEncoder.dok"></a></p>

<h2>onmt.PDBiEncoder</h2>

<p>PDBiEncoder is a pyramidal deep bidirectional Sequencer used for the source language.</p>

<p><a name="onmt.PDBiEncoder"></a></p>

<h3>onmt.PDBiEncoder(args, input)</h3>

<p>Create a pyrimal deep bidirectional encoder - each layers reconnect before starting another bidirectional layer</p>

<p>Parameters:</p>

<ul>
<li><code>args</code> - global arguments</li>
<li><code>input</code> - input neural network.</li>
</ul>

<p><a name="onmt.PDBiEncoder.load"></a></p>

<h3>onmt.PDBiEncoder.load(pretrained)</h3>

<p>Return a new PDBiEncoder using the serialized data <code>pretrained</code>. 
<a name="onmt.PDBiEncoder:serialize"></a></p>

<h3>onmt.PDBiEncoder:serialize()</h3>

<p>Return data to serialize. 
<a name="onmt.PDBiEncoder:contextSize"></a></p>

<h3>onmt.PDBiEncoder:contextSize(sourceSize, sourceLength)</h3>

<p>size of context vector</p>

<h4>Undocumented methods</h4>

<p><a name="onmt.PDBiEncoder.declareOpts"></a></p>

<ul>
<li><code>onmt.PDBiEncoder.declareOpts(cmd)</code>
<a name="onmt.PDBiEncoder:resetPreallocation"></a></li>
<li><code>onmt.PDBiEncoder:resetPreallocation()</code>
<a name="onmt.PDBiEncoder:maskPadding"></a></li>
<li><code>onmt.PDBiEncoder:maskPadding()</code>
<a name="onmt.PDBiEncoder:forward"></a></li>
<li><code>onmt.PDBiEncoder:forward(batch)</code>
<a name="onmt.PDBiEncoder:backward"></a></li>
<li><code>onmt.PDBiEncoder:backward(batch, gradStatesOutput, gradContextOutput)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.modules.ParallelClassNLLCriterion.dok"></a><p><a name="onmt.ParallelClassNLLCriterion.dok"></a></p>

<h2>onmt.ParallelClassNLLCriterion</h2>

<p>Define parallel ClassNLLCriterion.</p>

<h4>Undocumented methods</h4>

<p><a name="onmt.ParallelClassNLLCriterion"></a></p>

<ul>
<li><code>onmt.ParallelClassNLLCriterion(outputSizes)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.modules.Sequencer.dok"></a><p><a name="onmt.Sequencer.dok"></a></p>

<h2>onmt.Sequencer</h2>

<p>Sequencer is the base class for encoder and decoder models.
  Main task is to manage <code>self.net(t)</code>, the unrolled network
  used during training.</p>

<pre><code> :net(1) =&gt; :net(2) =&gt; ... =&gt; :net(n-1) =&gt; :net(n)
</code></pre>

<p><a name="onmt.Sequencer"></a></p>

<h3>onmt.Sequencer(network)</h3>

<p>Parameters:</p>

<ul>
<li><code>network</code> - recurrent step template.</li>
</ul>

<p><a name="onmt.Sequencer:net"></a></p>

<h3>onmt.Sequencer:net(t)</h3>

<p>Get access to the recurrent unit at a timestep.</p>

<p>Parameters:</p>

<ul>
<li><code>t</code> - timestep.</li>
</ul>

<p>Returns: The raw network clone at timestep t.
  When <code>evaluate()</code> has been called, cheat and return t=1.</p>

<p><a name="onmt.Sequencer:cloneId"></a></p>

<h3>onmt.Sequencer:cloneId(t)</h3>

<p>Return the id of the clone to use for timestep t or 0 if not using clones
<a name="onmt.Sequencer:training"></a></p>

<h3>onmt.Sequencer:training()</h3>

<p>Move the network to train mode. 
<a name="onmt.Sequencer:evaluate"></a></p>

<h3>onmt.Sequencer:evaluate()</h3>

<p>Move the network to evaluation mode. </p>
</div><div class='docSection'><a name="onmt.modules.WordEmbedding.dok"></a><p><a name="onmt.WordEmbedding.dok"></a></p>

<h2>onmt.WordEmbedding</h2>

<p>nn unit. Maps from word ids to embeddings. Slim wrapper around
nn.LookupTable to allow fixed and pretrained embeddings.</p>

<p><a name="onmt.WordEmbedding"></a></p>

<h3>onmt.WordEmbedding(vocabSize, vecSize, preTrained, fix)</h3>

<p>Parameters:</p>

<ul>
<li><code>vocabSize</code> - size of the vocabulary</li>
<li><code>vecSize</code> - size of the embedding</li>
<li><code>preTrainined</code> - path to a pretrained vector file</li>
<li><code>fix</code> - keep the weights of the embeddings fixed.</li>
</ul>

<h4>Undocumented methods</h4>

<p><a name="onmt.WordEmbedding:postParametersInitialization"></a></p>

<ul>
<li><code>onmt.WordEmbedding:postParametersInitialization()</code>
<a name="onmt.WordEmbedding:fixEmbeddings"></a></li>
<li><code>onmt.WordEmbedding:fixEmbeddings(fix)</code>
<a name="onmt.WordEmbedding:accGradParameters"></a></li>
<li><code>onmt.WordEmbedding:accGradParameters(input, gradOutput, scale)</code>
<a name="onmt.WordEmbedding:parameters"></a></li>
<li><code>onmt.WordEmbedding:parameters()</code></li>
</ul>
</div><div class='docSection'><a name="onmt.modules.init.dok"></a></div><div class='docSection'><a name="onmt.tagger.Tagger.dok"></a><p><a name="onmt.Tagger.dok"></a></p>

<h2>onmt.Tagger</h2>

<p><a name="onmt.Tagger:tag"></a></p>

<h3>onmt.Tagger:tag(src)</h3>

<p>Tag a batch of source sequences.</p>

<p>Parameters:</p>

<ul>
<li><code>src</code> - a batch of tables containing:

<ul>
<li><code>words</code>: the table of source words</li>
<li><code>features</code>: the table of feaures sequences (<code>src.features[i][j]</code> is the value of the ith feature of the jth token)</li>
</ul></li>
</ul>

<p>Returns:</p>

<ul>
<li><code>results</code> - a batch of tables containing:

<ul>
<li><code>words</code>: the table of target words</li>
<li><code>features</code>: the table of target features sequences</li>
</ul></li>
</ul>

<h4>Undocumented methods</h4>

<p><a name="onmt.Tagger.declareOpts"></a></p>

<ul>
<li><code>onmt.Tagger.declareOpts(cmd)</code>
<a name="onmt.Tagger"></a></li>
<li><code>onmt.Tagger(args)</code>
<a name="onmt.Tagger:buildInput"></a></li>
<li><code>onmt.Tagger:buildInput(tokens)</code>
<a name="onmt.Tagger:buildOutput"></a></li>
<li><code>onmt.Tagger:buildOutput(data)</code>
<a name="onmt.Tagger:buildData"></a></li>
<li><code>onmt.Tagger:buildData(src)</code>
<a name="onmt.Tagger:buildTargetWords"></a></li>
<li><code>onmt.Tagger:buildTargetWords(pred)</code>
<a name="onmt.Tagger:buildTargetFeatures"></a></li>
<li><code>onmt.Tagger:buildTargetFeatures(predFeats)</code>
<a name="onmt.Tagger:tagBatch"></a></li>
<li><code>onmt.Tagger:tagBatch(batch)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.tagger.init.dok"></a></div><div class='docSection'><a name="onmt.train.Checkpoint.dok"></a><p><a name="onmt.Checkpoint.dok"></a></p>

<h2>onmt.Checkpoint</h2>

<p>Class for saving and loading models during training.
<a name="onmt.Checkpoint:saveIteration"></a></p>

<h3>onmt.Checkpoint:saveIteration(iteration, epochState, batchOrder, verbose)</h3>

<p>Save the model and data in the middle of an epoch sorting the iteration. </p>

<h4>Undocumented methods</h4>

<p><a name="onmt.Checkpoint.declareOpts"></a></p>

<ul>
<li><code>onmt.Checkpoint.declareOpts(cmd)</code>
<a name="onmt.Checkpoint"></a></li>
<li><code>onmt.Checkpoint(opt, model, optim, dicts)</code>
<a name="onmt.Checkpoint:save"></a></li>
<li><code>onmt.Checkpoint:save(filePath, info)</code>
<a name="onmt.Checkpoint:saveEpoch"></a></li>
<li><code>onmt.Checkpoint:saveEpoch(validPpl, epochState, verbose)</code>
<a name="onmt.Checkpoint.loadFromCheckpoint"></a></li>
<li><code>onmt.Checkpoint.loadFromCheckpoint(opt)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.train.EpochState.dok"></a><p><a name="onmt.EpochState.dok"></a></p>

<h2>onmt.EpochState</h2>

<p>Class for managing the training process by logging and storing
  the state of the current epoch.</p>

<p><a name="onmt.EpochState"></a></p>

<h3>onmt.EpochState(epoch, startIterations, numIterations, learningRate)</h3>

<p>Initialize for epoch <code>epoch</code>
<a name="onmt.EpochState:update"></a></p>

<h3>onmt.EpochState:update(model, batch, loss)</h3>

<p>Update training status. Takes <code>batch</code> (described in data.lua) and last loss.
<a name="onmt.EpochState:log"></a></p>

<h3>onmt.EpochState:log(iteration)</h3>

<p>Log to status stdout. </p>

<h4>Undocumented methods</h4>

<p><a name="onmt.EpochState:reset"></a></p>

<ul>
<li><code>onmt.EpochState:reset()</code>
<a name="onmt.EpochState:getTime"></a></li>
<li><code>onmt.EpochState:getTime()</code></li>
</ul>
</div><div class='docSection'><a name="onmt.train.Optim.dok"></a><p><a name="onmt.Optim.dok"></a></p>

<h2>onmt.Optim</h2>

<hr>

<p><a name="onmt.Optim:updateLearningRate"></a></p>

<h3>onmt.Optim:updateLearningRate(score, epoch)</h3>

<p>decay learning rate if val perf does not improve or we hit the startDecayAt limit</p>

<h4>Undocumented methods</h4>

<p><a name="onmt.Optim.declareOpts"></a></p>

<ul>
<li><code>onmt.Optim.declareOpts(cmd)</code>
<a name="onmt.Optim"></a></li>
<li><code>onmt.Optim(args, optimStates)</code>
<a name="onmt.Optim:setOptimStates"></a></li>
<li><code>onmt.Optim:setOptimStates(num)</code>
<a name="onmt.Optim:zeroGrad"></a></li>
<li><code>onmt.Optim:zeroGrad(gradParams)</code>
<a name="onmt.Optim:prepareGrad"></a></li>
<li><code>onmt.Optim:prepareGrad(gradParams)</code>
<a name="onmt.Optim:updateParams"></a></li>
<li><code>onmt.Optim:updateParams(params, gradParams)</code>
<a name="onmt.Optim:getLearningRate"></a></li>
<li><code>onmt.Optim:getLearningRate()</code>
<a name="onmt.Optim:getStates"></a></li>
<li><code>onmt.Optim:getStates()</code></li>
</ul>
</div><div class='docSection'><a name="onmt.train.Trainer.dok"></a><p><a name="onmt.Trainer.dok"></a></p>

<h2>onmt.Trainer</h2>

<hr>

<h4>Undocumented methods</h4>

<p><a name="onmt.Trainer.declareOpts"></a></p>

<ul>
<li><code>onmt.Trainer.declareOpts(cmd)</code>
<a name="onmt.Trainer"></a></li>
<li><code>onmt.Trainer(args)</code>
<a name="onmt.Trainer:train"></a></li>
<li><code>onmt.Trainer:train(model, optim, trainData, validData, dataset, info)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.train.init.dok"></a></div><div class='docSection'><a name="onmt.translate.Advancer.dok"></a><p><a name="onmt.Advancer.dok"></a></p>

<h2>onmt.Advancer</h2>

<p>Class for specifying how to advance one step. A beam mainly consists of
  a list of <code>tokens</code> and a <code>state</code>. <code>tokens[t]</code> stores a flat tensors of size
  <code>batchSize * beamSize</code> representing tokens at step <code>t</code>. <code>state</code> can be either
  a tensor with first dimension size <code>batchSize * beamSize</code>, or an iterable
  object containing several such tensors.</p>

<p>Pseudocode:</p>

<pre><code>  finished = []

  beams = {}

  -- Initialize the beam.

  [ beams[1] ] &lt;-- initBeam()

  FOR t = 1, ... DO

    -- Update beam states based on new tokens.

    update([ beams[t] ])

    -- Expand beams by all possible tokens and return the scores.

    [ [scores] ] &lt;-- expand([ beams[t] ])

    -- Find k best next beams (maintained by BeamSearcher).

    _findKBest([beams], [ [scores] ])

    completed &lt;-- isComplete([ beams[t + 1] ])

    -- Remove completed hypotheses (maintained by BeamSearcher).

    finished += _completeHypotheses([beams], completed)

    IF all(completed) THEN

      BREAK

    END

  ENDWHILE
</code></pre>

<p>==================================================================</p>

<p><a name="onmt.Advancer:initBeam"></a></p>

<h3>onmt.Advancer:initBeam()</h3>

<p>Returns an initial beam.</p>

<p>Returns:</p>

<ul>
<li><code>beam</code> - an <code>onmt.translate.Beam</code> object.</li>
</ul>

<p><a name="onmt.Advancer:update"></a></p>

<h3>onmt.Advancer:update(beam)</h3>

<p>Updates beam states given new tokens.</p>

<p>Parameters:</p>

<ul>
<li><code>beam</code> - beam with updated token list.</li>
</ul>

<p><a name="onmt.Advancer:expand"></a></p>

<h3>onmt.Advancer:expand(beam)</h3>

<p>Expands beam by all possible tokens and returns the scores.</p>

<p>Parameters:</p>

<ul>
<li><code>beam</code> - an <code>onmt.translate.Beam</code> object.</li>
</ul>

<p>Returns:</p>

<ul>
<li><code>scores</code> - a 2D tensor of size <code>(batchSize * beamSize, numTokens)</code>.</li>
</ul>

<p><a name="onmt.Advancer:isComplete"></a></p>

<h3>onmt.Advancer:isComplete(beam)</h3>

<p>Checks which hypotheses in the beam are already finished.</p>

<p>Parameters:</p>

<ul>
<li><code>beam</code> - an <code>onmt.translate.Beam</code> object.</li>
</ul>

<p>Returns: a binary flat tensor of size <code>(batchSize * beamSize)</code>, indicating
  which hypotheses are finished.</p>

<p><a name="onmt.Advancer:setKeptStateIndexes"></a></p>

<h3>onmt.Advancer:setKeptStateIndexes(indexes)</h3>

<p>Specifies which states to keep track of. After beam search, those states
  can be retrieved during all steps along with the tokens. This is used
  for memory efficiency.</p>

<p>Parameters:</p>

<ul>
<li><code>indexes</code> - a table of iterators, specifying the indexes in the <code>states</code> to track.</li>
</ul>

<p><a name="onmt.Advancer:filter"></a></p>

<h3>onmt.Advancer:filter()</h3>

<p>Checks which hypotheses in the beam shall be pruned.</p>

<p>Parameters:</p>

<ul>
<li><code>beam</code> - an <code>onmt.translate.Beam</code> object.</li>
</ul>

<p>Returns: a binary flat tensor of size <code>(batchSize * beamSize)</code>, indicating
  which beams shall be pruned.</p>
</div><div class='docSection'><a name="onmt.translate.Beam.dok"></a><p><a name="onmt.Beam.dok"></a></p>

<h2>onmt.Beam</h2>

<p>Class for maintaining statistics of each step. A beam mainly consists of
  a list of tokens <code>tokens</code> and a state <code>state</code>. <code>tokens[t]</code> stores a flat tensor
  of size <code>batchSize * beamSize</code> representing the tokens at step <code>t</code>, while
  <code>state</code> can be either a tensor with first dimension size <code>batchSize * beamSize</code>,
  or an iterable object containing several such tensors.</p>

<p><a name="onmt.Beam"></a></p>

<h3>onmt.Beam(token, state, params, batchSize)</h3>

<p>Constructor. We allow users to either specify all initial hypotheses by
  passing in <code>token</code> and <code>state</code> with first dimension <code>batchSize * beamSize</code>
  such that there are <code>beamSize</code> initial hypotheses for every sequence in the
  batch and pass in the number of sequences <code>batchSize</code>, or only specify one
  hypothesis per sequence by passing <code>token</code> and <code>state</code> with first dimension
  <code>batchSize</code>, and then <code>onmt.translate.BeamSearcher</code> will pad with auxiliary
  hypotheses with scores <code>-inf</code> such that each sequence starts with <code>beamSize</code>
  hypotheses as in the former case.</p>

<p>Parameters:</p>

<ul>
<li><code>token</code> - tensor of size <code>(batchSize, vocabSize)</code> (if start with one initial
hypothesis per sequence) or <code>(batchSize * beamSize, vocabSize)</code> (if start with
<code>beamSize</code> initial hypotheses per sequence), or a list of such tensors.</li>
<li><code>state</code> - an iterable object, where the contained tensors should have the
same first dimension as <code>token</code>.</li>
<li><code>batchSize</code> - optional, number of sentences. Only necessary if
start with <code>beamSize</code> hypotheses per sequence. [<code>token:size(1)</code>]</li>
</ul>

<p><a name="onmt.Beam:getTokens"></a></p>

<h3>onmt.Beam:getTokens()</h3>

<p>Returns:</p>

<ul>
<li><code>tokens</code> - a list of tokens. Note that the start-of-sequence symbols are
also included. <code>tokens[t]</code> stores the tokens at step <code>t</code>, which is a tensor
of size <code>batchSize * beamSize</code>.</li>
</ul>

<p><a name="onmt.Beam:getState"></a></p>

<h3>onmt.Beam:getState()</h3>

<p>Returns:</p>

<ul>
<li><code>state</code> - an abstract iterable object as passed by constructor. Every tensor
inside the <code>state</code> has first dimension <code>batchSize * beamSize</code></li>
</ul>

<p><a name="onmt.Beam:getScores"></a></p>

<h3>onmt.Beam:getScores()</h3>

<p>Returns:</p>

<ul>
<li><code>scores</code> - a flat tensor storing the total scores for each batch. It is of
size <code>batchSize * beamSize</code>.</li>
</ul>

<p><a name="onmt.Beam:getBackPointer"></a></p>

<h3>onmt.Beam:getBackPointer()</h3>

<p>Returns:</p>

<ul>
<li><code>backPointer</code> - a flat tensor storing the backpointers for each batch. It is
of size <code>batchSize * beamSize</code></li>
</ul>

<p><a name="onmt.Beam:getRemaining"></a></p>

<h3>onmt.Beam:getRemaining()</h3>

<p>Returns the number of unfinished sequences. The finished sequences will be
  removed from batch.</p>

<p>Returns:</p>

<ul>
<li><code>remaining</code> - the number of unfinished sequences.</li>
</ul>

<p><a name="onmt.Beam:remaining2Orig"></a></p>

<h3>onmt.Beam:remaining2Orig(remainingId)</h3>

<p>Since finished sequences are being removed from the batch, this function
  provides a way to convert the remaining batch id to the original batch id.</p>

<p><a name="onmt.Beam:orig2Remaining"></a></p>

<h3>onmt.Beam:orig2Remaining(origId)</h3>

<p>Since finished sequences are being removed from the batch, this function
  provides a way to convert the original batch id to the remaining batch id.</p>

<p><a name="onmt.Beam:setState"></a></p>

<h3>onmt.Beam:setState(state)</h3>

<p>Set state.</p>

<p><a name="onmt.Beam:setScores"></a></p>

<h3>onmt.Beam:setScores(scores)</h3>

<p>Set scores.</p>

<p><a name="onmt.Beam:setBackPointer"></a></p>

<h3>onmt.Beam:setBackPointer(backPointer)</h3>

<p>Set backPointer.</p>
</div><div class='docSection'><a name="onmt.translate.BeamSearcher.dok"></a><p><a name="onmt.BeamSearcher.dok"></a></p>

<h2>onmt.BeamSearcher</h2>

<p>Class for managing the internals of the beam search process.</p>

<pre><code>  hyp1---hyp1---hyp1 -hyp1
      \             /
  hyp2 \-hyp2 /-hyp2--hyp2
             /      \
  hyp3---hyp3---hyp3 -hyp3
  ========================
</code></pre>

<p>Takes care of beams.</p>

<p><a name="onmt.BeamSearcher"></a></p>

<h3>onmt.BeamSearcher(advancer)</h3>

<p>Constructor</p>

<p>Parameters:</p>

<ul>
<li><code>advancer</code> - an <code>onmt.translate.Advancer</code> object.</li>
</ul>

<p><a name="onmt.BeamSearcher:search"></a></p>

<h3>onmt.BeamSearcher:search(beamSize, nBest, preFilterFactor, keepInitial)</h3>

<p>Performs beam search.</p>

<p>Parameters:</p>

<ul>
<li><code>beamSize</code> - beam size. [1]</li>
<li><code>nBest</code> - the <code>nBest</code> top hypotheses will be returned after beam search. [1]</li>
<li><code>preFilterFactor</code> - optional, set this only if filter is being used. Before
applying filters, hypotheses with top <code>beamSize * preFilterFactor</code> scores will
be considered. If the returned hypotheses voilate filters, then set this to a
larger value to consider more. [1]</li>
<li><code>keepInitial</code> - optional, whether return the initial token or not. [false]</li>
</ul>

<p>Returns: a table <code>finished</code>. <code>finished[b][n].score</code>, <code>finished[b][n].tokens</code>
and <code>finished[b][n].states</code> describe the n-th best hypothesis for b-th sample
in the batch.</p>
</div><div class='docSection'><a name="onmt.translate.DecoderAdvancer.dok"></a><p><a name="onmt.DecoderAdvancer.dok"></a></p>

<h2>onmt.DecoderAdvancer</h2>

<p>DecoderAdvancer is an implementation of the interface Advancer for
  specifyinghow to advance one step in decoder.</p>

<p><a name="onmt.DecoderAdvancer"></a></p>

<h3>onmt.DecoderAdvancer(decoder, batch, context, max_sent_length, max_num_unks, decStates, dicts, length_norm, coverage_norm, eos_norm, updateSeqLengthFunc)</h3>

<p>Constructor.</p>

<p>Parameters:</p>

<ul>
<li><code>decoder</code> - an <code>onmt.Decoder</code> object.</li>
<li><code>batch</code> - an <code>onmt.data.Batch</code> object.</li>
<li><code>context</code> - encoder output (batch x n x rnnSize).</li>
<li><code>max_sent_length</code> - optional, maximum output sentence length.</li>
<li><code>max_num_unks</code> - optional, maximum number of UNKs.</li>
<li><code>decStates</code> - optional, initial decoder states.</li>
<li><code>dicts</code> - optional, dictionary for additional features.</li>
<li><code>updateSeqLengthFunc</code> - optional, sequence length adaptation function after encoder</li>
</ul>

<p><a name="onmt.DecoderAdvancer:initBeam"></a></p>

<h3>onmt.DecoderAdvancer:initBeam()</h3>

<p>Returns an initial beam.</p>

<p>Returns:</p>

<ul>
<li><code>beam</code> - an <code>onmt.translate.Beam</code> object.</li>
</ul>

<p><a name="onmt.DecoderAdvancer:update"></a></p>

<h3>onmt.DecoderAdvancer:update(beam)</h3>

<p>Updates beam states given new tokens.</p>

<p>Parameters:</p>

<ul>
<li><code>beam</code> - beam with updated token list.</li>
</ul>

<p><a name="onmt.DecoderAdvancer:expand"></a></p>

<h3>onmt.DecoderAdvancer:expand(beam)</h3>

<p>Expand function. Expands beam by all possible tokens and returns the
  scores.</p>

<p>Parameters:</p>

<ul>
<li><code>beam</code> - an <code>onmt.translate.Beam</code> object.</li>
</ul>

<p>Returns:</p>

<ul>
<li><code>scores</code> - a 2D tensor of size <code>(batchSize * beamSize, numTokens)</code>.</li>
</ul>

<p><a name="onmt.DecoderAdvancer:isComplete"></a></p>

<h3>onmt.DecoderAdvancer:isComplete(beam)</h3>

<p>Checks which hypotheses in the beam are already finished. A hypothesis is
  complete if i) an onmt.Constants.EOS is encountered, or ii) the length of the
  sequence is greater than or equal to <code>max_sent_length</code>.</p>

<p>Parameters:</p>

<ul>
<li><code>beam</code> - an <code>onmt.translate.Beam</code> object.</li>
</ul>

<p>Returns: a binary flat tensor of size <code>(batchSize * beamSize)</code>, indicating
  which hypotheses are finished.</p>

<p><a name="onmt.DecoderAdvancer:filter"></a></p>

<h3>onmt.DecoderAdvancer:filter(beam)</h3>

<p>Checks which hypotheses in the beam shall be pruned. We disallow empty
 predictions, as well as predictions with more UNKs than <code>max_num_unks</code>.</p>

<p>Parameters:</p>

<ul>
<li><code>beam</code> - an <code>onmt.translate.Beam</code> object.</li>
</ul>

<p>Returns: a binary flat tensor of size <code>(batchSize * beamSize)</code>, indicating
  which beams shall be pruned.</p>
</div><div class='docSection'><a name="onmt.translate.PhraseTable.dok"></a><p><a name="onmt.PhraseTable.dok"></a></p>

<h2>onmt.PhraseTable</h2>

<p>Parse and lookup a words from a phrase table.</p>

<p><a name="onmt.PhraseTable:lookup"></a></p>

<h3>onmt.PhraseTable:lookup(word)</h3>

<p>Return the phrase table match for <code>word</code>. 
<a name="onmt.PhraseTable:contains"></a></p>

<h3>onmt.PhraseTable:contains(word)</h3>

<p>Return true if the phrase table contains the source word <code>word</code>. </p>

<h4>Undocumented methods</h4>

<p><a name="onmt.PhraseTable"></a></p>

<ul>
<li><code>onmt.PhraseTable(filePath)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.translate.Translator.dok"></a><p><a name="onmt.Translator.dok"></a></p>

<h2>onmt.Translator</h2>

<p><a name="onmt.Translator:translate"></a></p>

<h3>onmt.Translator:translate(src, gold)</h3>

<p>Translate a batch of source sequences.</p>

<p>Parameters:</p>

<ul>
<li><code>src</code> - a batch of tables containing:

<ul>
<li><code>words</code>: the table of source words</li>
<li><code>features</code>: the table of feaures sequences (<code>src.features[i][j]</code> is the value of the ith feature of the jth token)</li>
</ul></li>
<li><code>gold</code> - gold data to compute confidence score (same format as <code>src</code>)</li>
</ul>

<p>Returns:</p>

<ul>
<li><code>results</code> - a batch of tables containing:

<ul>
<li><code>goldScore</code>: if <code>gold</code> was given, this is the confidence score</li>
<li><code>preds</code>: an array of <code>args.n_best</code> tables containing:

<ul>
<li><code>words</code>: the table of target words</li>
<li><code>features</code>: the table of target features sequences</li>
<li><code>attention</code>: the attention vectors of each target word over the source words</li>
<li><code>score</code>: the confidence score of the prediction</li>
</ul></li>
</ul></li>
</ul>

<h4>Undocumented methods</h4>

<p><a name="onmt.Translator.declareOpts"></a></p>

<ul>
<li><code>onmt.Translator.declareOpts(cmd)</code>
<a name="onmt.Translator"></a></li>
<li><code>onmt.Translator(args)</code>
<a name="onmt.Translator:srcFeat"></a></li>
<li><code>onmt.Translator:srcFeat()</code>
<a name="onmt.Translator:buildInput"></a></li>
<li><code>onmt.Translator:buildInput(tokens)</code>
<a name="onmt.Translator:buildInputGold"></a></li>
<li><code>onmt.Translator:buildInputGold(tokens)</code>
<a name="onmt.Translator:buildOutput"></a></li>
<li><code>onmt.Translator:buildOutput(data)</code>
<a name="onmt.Translator:buildData"></a></li>
<li><code>onmt.Translator:buildData(src, gold)</code>
<a name="onmt.Translator:buildTargetWords"></a></li>
<li><code>onmt.Translator:buildTargetWords(pred, src, attn)</code>
<a name="onmt.Translator:buildTargetFeatures"></a></li>
<li><code>onmt.Translator:buildTargetFeatures(predFeats)</code>
<a name="onmt.Translator:translateBatch"></a></li>
<li><code>onmt.Translator:translateBatch(batch)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.translate.init.dok"></a></div><div class='docSection'><a name="onmt.utils.CrayonLogger.dok"></a><p><a name="onmt.CrayonLogger.dok"></a></p>

<h2>onmt.CrayonLogger</h2>

<h4>Undocumented methods</h4>

<p><a name="onmt.CrayonLogger.declareOpts"></a></p>

<ul>
<li><code>onmt.CrayonLogger.declareOpts(cmd)</code>
<a name="onmt.CrayonLogger"></a></li>
<li><code>onmt.CrayonLogger(args)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.utils.Cuda.dok"></a><p><a name="onmt.Cuda.getRNGStates"></a></p>

<h3>onmt.Cuda.getRNGStates()</h3>

<p>returns RNGState for CPU and enabled GPUs
<a name="onmt.Cuda.setRNGStates"></a></p>

<h3>onmt.Cuda.setRNGStates(rngStates, verbose)</h3>

<p>set RNGState from saved state
<a name="onmt.Cuda.convert"></a></p>

<h3>onmt.Cuda.convert(obj)</h3>

<p>Recursively move all supported objects in <code>obj</code> on the GPU.
  When using CPU only, converts to float instead of the default double.</p>

<p><a name="onmt.Cuda.synchronize"></a></p>

<h3>onmt.Cuda.synchronize()</h3>

<p>Synchronize operations on current device if working on GPU.
  Do nothing otherwise.</p>

<p><a name="onmt.Cuda.gpuCount"></a></p>

<h3>onmt.Cuda.gpuCount()</h3>

<p>Number of available GPU.</p>

<p><a name="onmt.Cuda.freeMemory"></a></p>

<h3>onmt.Cuda.freeMemory()</h3>

<p>Free memory on the current GPU device.</p>

<h4>Undocumented methods</h4>

<p><a name="onmt.Cuda.declareOpts"></a></p>

<ul>
<li><code>onmt.Cuda.declareOpts(cmd)</code>
<a name="onmt.Cuda.init"></a></li>
<li><code>onmt.Cuda.init(opt, masterGPU)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.utils.Dict.dok"></a><p><a name="onmt.Dict.dok"></a></p>

<h2>onmt.Dict</h2>

<p><a name="onmt.Dict:size"></a></p>

<h3>onmt.Dict:size()</h3>

<p>Return the number of entries in the dictionary. 
<a name="onmt.Dict:loadFile"></a></p>

<h3>onmt.Dict:loadFile(filename)</h3>

<p>Load entries from a file. 
<a name="onmt.Dict:writeFile"></a></p>

<h3>onmt.Dict:writeFile(filename)</h3>

<p>Write entries to a file. 
<a name="onmt.Dict:lookup"></a></p>

<h3>onmt.Dict:lookup(key)</h3>

<p>Lookup <code>key</code> in the dictionary: it can be an index or a string. 
<a name="onmt.Dict:addSpecial"></a></p>

<h3>onmt.Dict:addSpecial(label, idx)</h3>

<p>Mark this <code>label</code> and <code>idx</code> as special (i.e. will not be pruned). 
<a name="onmt.Dict:addSpecials"></a></p>

<h3>onmt.Dict:addSpecials(labels)</h3>

<p>Mark all labels in <code>labels</code> as specials (i.e. will not be pruned). 
<a name="onmt.Dict:add"></a></p>

<h3>onmt.Dict:add(label, idx)</h3>

<p>Add <code>label</code> in the dictionary. Use <code>idx</code> as its index if given. 
<a name="onmt.Dict:prune"></a></p>

<h3>onmt.Dict:prune(size)</h3>

<p>Return a new dictionary with the <code>size</code> most frequent entries. 
<a name="onmt.Dict:pruneByMinFrequency"></a></p>

<h3>onmt.Dict:pruneByMinFrequency(minFrequency)</h3>

<p>Return a new dictionary with entries appearing at least <code>minFrequency</code> times. 
<a name="onmt.Dict:convertToIdx"></a></p>

<h3>onmt.Dict:convertToIdx(labels, unkWord, bosWord, eosWord)</h3>

<p>Convert <code>labels</code> to indices. Use <code>unkWord</code> if not found.
  Optionally insert <code>bosWord</code> at the beginning and <code>eosWord</code> at the end.</p>

<p><a name="onmt.Dict:convertToLabels"></a></p>

<h3>onmt.Dict:convertToLabels(idx, stop)</h3>

<p>Convert <code>idx</code> to labels. If index <code>stop</code> is reached, convert it and return. </p>

<h4>Undocumented methods</h4>

<p><a name="onmt.Dict"></a></p>

<ul>
<li><code>onmt.Dict(data)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.utils.ExtendedCmdLine.dok"></a><p><a name="onmt.ExtendedCmdLine:loadConfig"></a></p>

<h3>onmt.ExtendedCmdLine:loadConfig(filename, opt)</h3>

<p>Override options with option values set in file <code>filename</code>. 
<a name="onmt.ExtendedCmdLine.isInt"></a></p>

<h3>onmt.ExtendedCmdLine.isInt(minValue, maxValue)</h3>

<p>Check if is integer between minValue and maxValue.
<a name="onmt.ExtendedCmdLine.isUInt"></a></p>

<h3>onmt.ExtendedCmdLine.isUInt(maxValue)</h3>

<p>Check if is positive integer.
<a name="onmt.ExtendedCmdLine.listUInt"></a></p>

<h3>onmt.ExtendedCmdLine.listUInt(v)</h3>

<p>Check if list of positive integers.
<a name="onmt.ExtendedCmdLine.isFloat"></a></p>

<h3>onmt.ExtendedCmdLine.isFloat(minValue, maxValue)</h3>

<p>Check if value between minValue and maxValue.
<a name="onmt.ExtendedCmdLine.nonEmpty"></a></p>

<h3>onmt.ExtendedCmdLine.nonEmpty(v)</h3>

<p>Check if non empty.
<a name="onmt.ExtendedCmdLine.fileExists"></a></p>

<h3>onmt.ExtendedCmdLine.fileExists(v)</h3>

<p>Check if the corresponding file exists.
<a name="onmt.ExtendedCmdLine.fileNullOrExists"></a></p>

<h3>onmt.ExtendedCmdLine.fileNullOrExists(v)</h3>

<p>Check non set or if the corresponding file exists.
<a name="onmt.ExtendedCmdLine.dirStructure"></a></p>

<h3>onmt.ExtendedCmdLine.dirStructure(files)</h3>

<p>Check it is a directory and some file exists</p>

<h4>Undocumented methods</h4>

<p><a name="onmt.ExtendedCmdLine"></a></p>

<ul>
<li><code>onmt.ExtendedCmdLine(script)</code>
<a name="onmt.ExtendedCmdLine:help"></a></li>
<li><code>onmt.ExtendedCmdLine:help(arg, doMd)</code>
<a name="onmt.ExtendedCmdLine:error"></a></li>
<li><code>onmt.ExtendedCmdLine:error(msg)</code>
<a name="onmt.ExtendedCmdLine:option"></a></li>
<li><code>onmt.ExtendedCmdLine:option(key, default, help, _meta_)</code>
<a name="onmt.ExtendedCmdLine:logConfig"></a></li>
<li><code>onmt.ExtendedCmdLine:logConfig(opt)</code>
<a name="onmt.ExtendedCmdLine:dumpConfig"></a></li>
<li><code>onmt.ExtendedCmdLine:dumpConfig(opt, filename)</code>
<a name="onmt.ExtendedCmdLine:parse"></a></li>
<li><code>onmt.ExtendedCmdLine:parse(arg)</code>
<a name="onmt.ExtendedCmdLine:setCmdLineOptions"></a></li>
<li><code>onmt.ExtendedCmdLine:setCmdLineOptions(moduleOptions, group)</code>
<a name="onmt.ExtendedCmdLine.getModuleOpts"></a></li>
<li><code>onmt.ExtendedCmdLine.getModuleOpts(args, moduleOptions)</code>
<a name="onmt.ExtendedCmdLine.getArgument"></a></li>
<li><code>onmt.ExtendedCmdLine.getArgument(args, optName)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.utils.Features.dok"></a><h3>Features.lua</h3>

<p>tds is lazy loaded.</p>
</div><div class='docSection'><a name="onmt.utils.FileReader.dok"></a><p><a name="onmt.FileReader.dok"></a></p>

<h2>onmt.FileReader</h2>

<p><a name="onmt.FileReader:next"></a></p>

<h3>onmt.FileReader:next()</h3>

<p>Read next line in the file and split it on spaces. If EOF is reached, returns nil. </p>

<h4>Undocumented methods</h4>

<p><a name="onmt.FileReader"></a></p>

<ul>
<li><code>onmt.FileReader(filename, idxSent, featSequence)</code>
<a name="onmt.FileReader:close"></a></li>
<li><code>onmt.FileReader:close()</code></li>
</ul>
</div><div class='docSection'><a name="onmt.utils.Logger.dok"></a><p><a name="onmt.Logger.dok"></a></p>

<h2>onmt.Logger</h2>

<p>Logger is a class used for maintaining logs in a log file.</p>

<p><a name="onmt.Logger"></a></p>

<h3>onmt.Logger(logFile, disableLogs, logLevel)</h3>

<p>Construct a Logger object.</p>

<p>Parameters:</p>

<ul>
<li><code>logFile</code> - Outputs logs to a file under this path instead of stdout. [&#39;&#39;]</li>
<li><code>disableLogs</code> - If = true, output nothing. [false]</li>
<li><code>logLevel</code> - Outputs logs at this level and above. Possible options are: DEBUG, INFO, WARNING and ERROR. [&#39;INFO&#39;]</li>
</ul>

<p>Example:</p>

<pre><code>logger = onmt.utils.Logger.new(&#39;log.txt&#39;)
logger:info(&#39;%s is an extension of OpenNMT.&#39;, &#39;Im2Text&#39;)
logger:shutDown()
</code></pre>

<p><a name="onmt.Logger:log"></a></p>

<h3>onmt.Logger:log(message, level)</h3>

<p>Log a message at a specified level.</p>

<p>Parameters:</p>

<ul>
<li><code>message</code> - the message to log.</li>
<li><code>level</code> - the desired message level. [&#39;INFO&#39;]</li>
</ul>

<p><a name="onmt.Logger:info"></a></p>

<h3>onmt.Logger:info(...)</h3>

<p>Log a message at &#39;INFO&#39; level.</p>

<p>Parameters:</p>

<ul>
<li><code>message</code> - the message to log. Supports formatting string.</li>
</ul>

<p><a name="onmt.Logger:warning"></a></p>

<h3>onmt.Logger:warning(...)</h3>

<p>Log a message at &#39;WARNING&#39; level.</p>

<p>Parameters:</p>

<ul>
<li><code>message</code> - the message to log. Supports formatting string.</li>
</ul>

<p><a name="onmt.Logger:error"></a></p>

<h3>onmt.Logger:error(...)</h3>

<p>Log a message at &#39;ERROR&#39; level.</p>

<p>Parameters:</p>

<ul>
<li><code>message</code> - the message to log. Supports formatting string.</li>
</ul>

<p><a name="onmt.Logger:debug"></a></p>

<h3>onmt.Logger:debug(...)</h3>

<p>Log a message at &#39;DEBUG&#39; level.</p>

<p>Parameters:</p>

<ul>
<li><code>message</code> - the message to log. Supports formatting string.</li>
</ul>

<p><a name="onmt.Logger:writeMsg"></a></p>

<h3>onmt.Logger:writeMsg(...)</h3>

<p>Log a message as exactly it is.</p>

<p>Parameters:</p>

<ul>
<li><code>message</code> - the message to log. Supports formatting string.</li>
</ul>

<p><a name="onmt.Logger:setVisibleLevel"></a></p>

<h3>onmt.Logger:setVisibleLevel(level)</h3>

<p>Set the visible message level. Lower level messages will be muted.</p>

<p>Parameters:</p>

<ul>
<li><code>level</code> - &#39;DEBUG&#39;, &#39;INFO&#39;, &#39;WARNING&#39; or &#39;ERROR&#39;.</li>
</ul>

<p><a name="onmt.Logger:shutDown"></a></p>

<h3>onmt.Logger:shutDown()</h3>

<p>Deconstructor. Close the log file.</p>

<h4>Undocumented methods</h4>

<p><a name="onmt.Logger.declareOpts"></a></p>

<ul>
<li><code>onmt.Logger.declareOpts(cmd)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.utils.Memory.dok"></a><p><a name="onmt.Memory.optimize"></a></p>

<h3>onmt.Memory.optimize(model, batch, verbose)</h3>

<p>Optimize memory usage of Neural Machine Translation.</p>

<p>Parameters:</p>

<ul>
<li><code>model</code> - a table containing encoder and decoder</li>
<li><code>batch</code> - a Batch object</li>
<li><code>verbose</code> - produce output or not</li>
</ul>

<p>Example:</p>

<p>local model = {}
  model.encoder = onmt.Models.buildEncoder(...)
  model.decoder = onmt.Models.buildDecoder(...)
  Memory.optimize(model, batch, verbose)</p>

<h4>Undocumented methods</h4>

<p><a name="onmt.Memory.declareOpts"></a></p>

<ul>
<li><code>onmt.Memory.declareOpts(cmd)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.utils.MemoryOptimizer.dok"></a><p><a name="onmt.MemoryOptimizer.dok"></a></p>

<h2>onmt.MemoryOptimizer</h2>

<p>MemoryOptimizer is a class used for optimizing memory usage</p>

<p><a name="onmt.MemoryOptimizer"></a></p>

<h3>onmt.MemoryOptimizer(modules)</h3>

<p>Construct a MemoryOptimizer object. In this function, forward and backward function will
 be overwrited to record input and gradOutput in order to determine which tensors can be shared.</p>

<p>Parameters:</p>

<ul>
<li><code>modules</code> - a list of modules to optimize.</li>
</ul>

<p>Example:</p>

<p>local memoryOptimizer = onmt.utils.MemoryOptimizer.new(model) -- prepare memory optimization.
  model:forward(...) -- initialize output tensors
  model:backward(...) -- intialize gradInput tensors
  memoryOptimizer.optimize(model) -- actual optimization by marking shared tensors</p>

<p><a name="onmt.MemoryOptimizer:optimize"></a></p>

<h3>onmt.MemoryOptimizer:optimize()</h3>

<p>Enable memory optimization by marking tensors to share. Note that the modules must have been initialized
by calling forward() and backward() before calling this function and after calling the MemoryOptimizer constructor.</p>

<p>Returns:</p>

<ol>
<li><code>sharedSize</code> - shared tensor size</li>
<li><code>totSize</code> - total tensor size</li>
</ol>
</div><div class='docSection'><a name="onmt.utils.Parallel.dok"></a><h3>Parallel.lua</h3>

<p>This file provides generic parallel class - allowing to run functions
  in different threads and on different GPU</p>

<p><a name="onmt.Parallel.launch"></a></p>

<h3>onmt.Parallel.launch(closure, endCallback)</h3>

<p>Launch function in parallel on different threads. 
<a name="onmt.Parallel.accGradParams"></a></p>

<h3>onmt.Parallel.accGradParams(gradParams, batches)</h3>

<p>Accumulate the gradient parameters from the different parallel threads. 
<a name="onmt.Parallel.updateAndSync"></a></p>

<h3>onmt.Parallel.updateAndSync(masterParams, replicaGradParams, replicaParams, gradBuffer, masterGPU, gmutexId)</h3>

<p>In async mode, sync the parameters from all replica to master replica. 
<a name="onmt.Parallel.syncParams"></a></p>

<h3>onmt.Parallel.syncParams(params)</h3>

<p>Sync parameters from main model to different parallel threads. </p>

<h4>Undocumented methods</h4>

<p><a name="onmt.Parallel.getCounter"></a></p>

<ul>
<li><code>onmt.Parallel.getCounter()</code>
<a name="onmt.Parallel.gmutexId"></a></li>
<li><code>onmt.Parallel.gmutexId()</code>
<a name="onmt.Parallel.init"></a></li>
<li><code>onmt.Parallel.init(opt)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.utils.Profiler.dok"></a><p><a name="onmt.Profiler.dok"></a></p>

<h2>onmt.Profiler</h2>

<p>Profile is a class used for generating profiling of a training</p>

<p><a name="onmt.Profiler"></a></p>

<h3>onmt.Profiler(opt)</h3>

<p>Profiler object</p>

<p>To avoid concurrency problem for parallel processing, each thread should have its own Profiler.
Profiles can be embedded.</p>

<p>Parameters:</p>

<ul>
<li><code>doProfile</code> - enable profiling</li>
</ul>

<p>Documentation:
  Profile is recording/aggregating time spent in sections. Sections have hierarchical structure.
  A section is opened with <code>P:start(&quot;name&quot;)</code> and closed with <code>P:close(&quot;name&quot;)</code>.
  Start and Stop command can be stacked: <code>P:stop(&quot;b&quot;):start(&quot;a&quot;)</code> or combined: <code>P:start(&quot;a.b&quot;)</code></p>

<p>Example:
    -- global profiler initialization
    globalProfiler = onmt.utils.Profiler.new(opt)</p>

<pre><code>-- thread-specific profiler
  _G.profiler = onmt.utils.Profiler.new(opt)

  _G.profiler:reset()

  _G.profiler:start(&quot;encoder&quot;)
  [...]
  _G.profiler:stop(&quot;encoder&quot;):start(&quot;decoder&quot;)
  [...]
  _G.profiler:stop(&quot;decoder&quot;)

  local profile = _G.profiler.dump()

-- adds up thread profile
globalProfiler:add(profile)

Logger:info(globalProfiler:log())
</code></pre>

<p><a name="onmt.Profiler:reset"></a></p>

<h3>onmt.Profiler:reset()</h3>

<p>Reset Profiler.
<a name="onmt.Profiler:start"></a></p>

<h3>onmt.Profiler:start(name)</h3>

<p>Start recording a section.
<a name="onmt.Profiler:stop"></a></p>

<h3>onmt.Profiler:stop(name)</h3>

<p>Stop recording a section.
<a name="onmt.Profiler:dump"></a></p>

<h3>onmt.Profiler:dump()</h3>

<p>Dump profile.
<a name="onmt.Profiler:add"></a></p>

<h3>onmt.Profiler:add(profile)</h3>

<p>Aggregage profiles with a previous dump in the current namespace
<a name="onmt.Profiler:log"></a></p>

<h3>onmt.Profiler:log(prefix)</h3>

<p>Returns text string with log structured by sub level.
e.g. train:{total:23, encoder_fwd:10, encoder_bwd:14}</p>

<h4>Undocumented methods</h4>

<p><a name="onmt.Profiler.declareOpts"></a></p>

<ul>
<li><code>onmt.Profiler.declareOpts(cmd)</code>
<a name="onmt.Profiler.addHook"></a></li>
<li><code>onmt.Profiler.addHook(module, name)</code></li>
</ul>
</div><div class='docSection'><a name="onmt.utils.String.dok"></a></div><div class='docSection'><a name="onmt.utils.Table.dok"></a><h3>Table.lua</h3>

<p>tds is lazy loaded.</p>
</div><div class='docSection'><a name="onmt.utils.Tensor.dok"></a></div><div class='docSection'><a name="onmt.utils.init.dok"></a></div>
</section>
</div>
</body>
</html>
