<p><a name="onmt.MemoryOptimizer.dok"></a></p>

<h2>onmt.MemoryOptimizer</h2>

<p>MemoryOptimizer is a class used for optimizing memory usage</p>

<p><a name="onmt.MemoryOptimizer"></a></p>

<h3>onmt.MemoryOptimizer(modules)</h3>

<p>Construct a MemoryOptimizer object. In this function, forward and backward function will
 be overwrited to record input and gradOutput in order to determine which tensors can be shared.</p>

<p>Parameters:</p>

<ul>
<li><code>modules</code> - a list of modules to optimize.</li>
</ul>

<p>Example:</p>

<p>local memoryOptimizer = onmt.utils.MemoryOptimizer.new(model) -- prepare memory optimization.
  model:forward(...) -- initialize output tensors
  model:backward(...) -- intialize gradInput tensors
  memoryOptimizer.optimize(model) -- actual optimization by marking shared tensors</p>

<p><a name="onmt.MemoryOptimizer:optimize"></a></p>

<h3>onmt.MemoryOptimizer:optimize()</h3>

<p>Enable memory optimization by marking tensors to share. Note that the modules must have been initialized
by calling forward() and backward() before calling this function and after calling the MemoryOptimizer constructor.</p>

<p>Returns:</p>

<ol>
<li><code>sharedSize</code> - shared tensor size</li>
<li><code>totSize</code> - total tensor size</li>
</ol>
