<h3>Parallel.lua</h3>

<p>This file provides generic parallel class - allowing to run functions
  in different threads and on different GPU</p>

<p><a name="onmt.Parallel.launch"></a></p>

<h3>onmt.Parallel.launch(closure, endCallback)</h3>

<p>Launch function in parallel on different threads. 
<a name="onmt.Parallel.accGradParams"></a></p>

<h3>onmt.Parallel.accGradParams(gradParams, batches)</h3>

<p>Accumulate the gradient parameters from the different parallel threads. 
<a name="onmt.Parallel.updateAndSync"></a></p>

<h3>onmt.Parallel.updateAndSync(masterParams, replicaGradParams, replicaParams, gradBuffer, masterGPU, gmutexId)</h3>

<p>In async mode, sync the parameters from all replica to master replica. 
<a name="onmt.Parallel.syncParams"></a></p>

<h3>onmt.Parallel.syncParams(params)</h3>

<p>Sync parameters from main model to different parallel threads. </p>

<h4>Undocumented methods</h4>

<p><a name="onmt.Parallel.getCounter"></a></p>

<ul>
<li><code>onmt.Parallel.getCounter()</code>
<a name="onmt.Parallel.gmutexId"></a></li>
<li><code>onmt.Parallel.gmutexId()</code>
<a name="onmt.Parallel.init"></a></li>
<li><code>onmt.Parallel.init(opt)</code></li>
</ul>
